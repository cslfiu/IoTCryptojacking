{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cc5b4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/WebOS_binary.csv') #\n",
    "df2 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Server_Binary.csv') #\n",
    "df3 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Raspberry_Webmine_Robust.csv')\n",
    "df4 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Raspberry_Binary.csv') #\n",
    "df5 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Raspberry_Webmine_Aggressive.csv')\n",
    "df6 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Raspberry_WebminePool_Aggressive.csv')\n",
    "df7 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Server_WebminePool_Aggressive.csv') #\n",
    "df32 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Server_WebminePool_Robust.csv') #\n",
    "df33 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Raspberry_WebminePool_Stealthy.csv') #\n",
    "df34 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Raspberry_WebminePool_Robust.csv') #\n",
    "df35 = pd.read_csv('/home/csl/Desktop/ege/new_captures/malicious/Desktop_WebminePool_Aggressive.csv') #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign-1 csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df8 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/interactive_01.csv') #\n",
    "df9 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/interactive_02.csv') #\n",
    "df10 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/interactive_03.csv') #\n",
    "df11 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/interactive_04.csv') #\n",
    "df12 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/interactive_05.csv') #\n",
    "df13 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/interactive_06.csv') #\n",
    "df14 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_1page_01.csv') #\n",
    "df15 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_1page_02.csv') #\n",
    "df16 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_1page_03.csv') #\n",
    "df17 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_1page_04.csv') #\n",
    "df18 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_1page_05.csv') #\n",
    "df19 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/bulk_xs_04.csv') #\n",
    "df20 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/bulk_xs_05.csv') #\n",
    "df21 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/video_180s480p_01.csv') #\n",
    "df22 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/video_180s480p_02.csv') #\n",
    "df23 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/video_x1_04.csv') #\n",
    "df24 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_multiple_04.csv') #\n",
    "df25 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/bulk_xs_01.csv') #\n",
    "df26 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/bulk_xs_09.csv') #\n",
    "df27 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/bulk_xs_06.csv') #\n",
    "df28 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/bulk_xs_03.csv') #\n",
    "df29 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_multiple_03.csv') #\n",
    "df30 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_multiple_05.csv') #\n",
    "df31 = pd.read_csv('/home/csl/Desktop/ege/new_captures/benign-1/web_multiple_06.csv') #\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7873a888",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59635\n",
      "df25 -->> 625216\n",
      "df26 -->> 266935\n",
      "df27 -->> 453471\n",
      "df28 -->> 654495\n",
      "df29 -->> 6764\n",
      "df30 -->> 25300\n",
      "df31 -->> 3689\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n",
    "print(\"df24 -->> {}\".format(len(df24)))\n",
    "print(\"df25 -->> {}\".format(len(df25)))\n",
    "print(\"df26 -->> {}\".format(len(df26)))\n",
    "print(\"df27 -->> {}\".format(len(df27)))\n",
    "print(\"df28 -->> {}\".format(len(df28)))\n",
    "print(\"df29 -->> {}\".format(len(df29)))\n",
    "print(\"df30 -->> {}\".format(len(df30)))\n",
    "print(\"df31 -->> {}\".format(len(df31)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe26459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#                     Filtering                                 #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c319cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "df24.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df25.insert(7, \"Is_malicious\", 0)\n",
    "df26.insert(7, \"Is_malicious\", 0)\n",
    "df27.insert(7, \"Is_malicious\", 0)\n",
    "df28.insert(7, \"Is_malicious\", 0)\n",
    "df29.insert(7, \"Is_malicious\", 0)\n",
    "df30.insert(7, \"Is_malicious\", 0)\n",
    "df31.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c789de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 41572\n",
      "df2 -->> 1198039\n",
      "df3 -->> 3519\n",
      "df4 -->> 11745\n",
      "df5 -->> 12871\n",
      "df6 -->> 19643\n",
      "df7 -->> 2539\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59619\n",
      "df25 -->> 625194\n",
      "df26 -->> 266935\n",
      "df27 -->> 453466\n",
      "df28 -->> 654479\n",
      "df29 -->> 6764\n",
      "df30 -->> 25288\n",
      "df31 -->> 3689\n",
      "df32 -->> 16744\n",
      "df33 -->> 9880\n",
      "df34 -->> 6406\n",
      "df35 -->> 234272\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1.dropna())))\n",
    "print(\"df2 -->> {}\".format(len(df2.dropna())))\n",
    "print(\"df3 -->> {}\".format(len(df3.dropna())))\n",
    "print(\"df4 -->> {}\".format(len(df4.dropna())))\n",
    "print(\"df5 -->> {}\".format(len(df5.dropna())))\n",
    "print(\"df6 -->> {}\".format(len(df6.dropna())))\n",
    "print(\"df7 -->> {}\".format(len(df7.dropna())))\n",
    "print(\"df8 -->> {}\".format(len(df8.dropna())))\n",
    "print(\"df9 -->> {}\".format(len(df9.dropna())))\n",
    "print(\"df10 -->> {}\".format(len(df10.dropna())))\n",
    "print(\"df11 -->> {}\".format(len(df11.dropna())))\n",
    "print(\"df12 -->> {}\".format(len(df12.dropna())))\n",
    "print(\"df13 -->> {}\".format(len(df13.dropna())))\n",
    "print(\"df14 -->> {}\".format(len(df14.dropna())))\n",
    "print(\"df15 -->> {}\".format(len(df15.dropna())))\n",
    "print(\"df16 -->> {}\".format(len(df16.dropna())))\n",
    "print(\"df17 -->> {}\".format(len(df17.dropna())))\n",
    "print(\"df18 -->> {}\".format(len(df18.dropna())))\n",
    "print(\"df19 -->> {}\".format(len(df19.dropna())))\n",
    "print(\"df20 -->> {}\".format(len(df20.dropna())))\n",
    "print(\"df21 -->> {}\".format(len(df21.dropna())))\n",
    "print(\"df22 -->> {}\".format(len(df22.dropna())))\n",
    "print(\"df23 -->> {}\".format(len(df23.dropna())))\n",
    "print(\"df24 -->> {}\".format(len(df24.dropna())))\n",
    "print(\"df25 -->> {}\".format(len(df25.dropna())))\n",
    "print(\"df26 -->> {}\".format(len(df26.dropna())))\n",
    "print(\"df27 -->> {}\".format(len(df27.dropna())))\n",
    "print(\"df28 -->> {}\".format(len(df28.dropna())))\n",
    "print(\"df29 -->> {}\".format(len(df29.dropna())))\n",
    "print(\"df30 -->> {}\".format(len(df30.dropna())))\n",
    "print(\"df31 -->> {}\".format(len(df31.dropna())))\n",
    "print(\"df32 -->> {}\".format(len(df32.dropna())))\n",
    "print(\"df33 -->> {}\".format(len(df33.dropna())))\n",
    "print(\"df34 -->> {}\".format(len(df34.dropna())))\n",
    "print(\"df35 -->> {}\".format(len(df35.dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a53e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(a,b,x):\n",
    "    \n",
    "    df_malicious = a.copy()\n",
    "    df_benign    = b.copy()\n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious['id']= np.floor(df_malicious.index.array/10)\n",
    "    df_benign.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign['id']= np.floor(df_benign.index.array/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    tf1=tsfresh.extract_features(df_malicious,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "\n",
    "    \n",
    "    \n",
    "    tf2=tsfresh.extract_features(df_benign,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "\n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "\n",
    "    features=pd.concat([tf1,tf2])\n",
    "\n",
    "\n",
    "    features2 = features.copy()\n",
    "    features2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    y = pd.Series(data = features2['class'], index=features2.index)\n",
    "    \n",
    "    from tsfresh.examples import load_robot_execution_failures\n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "    relevance_table = calculate_relevance_table(features2, y)\n",
    "    relevance_table = relevance_table[relevance_table.relevant]\n",
    "    relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "\n",
    "    relevance_table\n",
    "    \n",
    "    best_features = relevance_table[relevance_table['p_value'] <= 0.05]\n",
    "\n",
    "    df_ML = pd.DataFrame()\n",
    "\n",
    "    for pkt in best_features:\n",
    "        df_ML[best_features.feature] = features[best_features.feature]\n",
    "\n",
    "    final = ML_Process(df_ML,x)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e0a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Process(df_ML,x):\n",
    "    df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    #X = df_finalized[['Time', 'Length','Protocol']].values\n",
    "    X = df_ML.drop('class',axis=1).to_numpy()\n",
    "    #y = df_finalized[['Is_malicious']]\n",
    "    y = df_ML['class'].to_numpy()\n",
    "\n",
    "\n",
    "    #print(X,y)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X[0])):\n",
    "        X[:, i] = Le.fit_transform(X[:, i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    "\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "        ('SVM-linear-scale-1', SVC(C = 1, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-1', SVC(C = 1, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-1', SVC(C = 1, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-1', SVC(C = 1, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-1', SVC(C = 1, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-1', SVC(C = 1, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-1', SVC(C = 1, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-1', SVC(C = 1, kernel = 'sigmoid',gamma ='auto')),\n",
    "        ('SVM-linear-scale-2', SVC(C = 2, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-2', SVC(C = 2, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-2', SVC(C = 2, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-2', SVC(C = 2, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-2', SVC(C = 2, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-2', SVC(C = 2, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-2', SVC(C = 2, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-2', SVC(C = 2, kernel = 'sigmoid',gamma ='auto'))\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        df_resulta = df_results.append(dfs)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9d3e1be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1000\n",
      "benign: 1000\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1000\n",
      "benign: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████| 100/100 [00:00<00:00, 333.74it/s]\n",
      "Feature Extraction: 100%|████████████████████| 100/100 [00:00<00:00, 348.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "SVM-linear-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.73      0.83      0.78        23\n",
      "      benign       0.83      0.74      0.78        27\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.78      0.78        50\n",
      "weighted avg       0.79      0.78      0.78        50\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.004958    0.003295       0.866667                 0.872222   \n",
      "1  0.004817    0.002979       0.833333                 0.843333   \n",
      "2  0.002984    0.002905       0.800000                 0.825926   \n",
      "3  0.003961    0.002876       0.700000                 0.700893   \n",
      "4  0.004283    0.002876       0.700000                 0.708333   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.866667          0.865460      0.888393  SVM-linear-scale-1  \n",
      "1              0.833333          0.829221      0.800905  SVM-linear-scale-1  \n",
      "2              0.800000          0.798214      0.866071  SVM-linear-scale-1  \n",
      "3              0.700000          0.699666      0.822222  SVM-linear-scale-1  \n",
      "4              0.700000          0.696970      0.804444  SVM-linear-scale-1  \n",
      "SVM-poly-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.88      0.96      0.92        23\n",
      "      benign       0.96      0.89      0.92        27\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.92      0.92      0.92        50\n",
      "weighted avg       0.92      0.92      0.92        50\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.004958    0.003295       0.866667                 0.872222   \n",
      "1  0.004817    0.002979       0.833333                 0.843333   \n",
      "2  0.002984    0.002905       0.800000                 0.825926   \n",
      "3  0.003961    0.002876       0.700000                 0.700893   \n",
      "4  0.004283    0.002876       0.700000                 0.708333   \n",
      "5  0.001550    0.002923       0.900000                 0.902222   \n",
      "6  0.001356    0.002928       0.800000                 0.808889   \n",
      "7  0.001301    0.002926       0.900000                 0.902222   \n",
      "8  0.001295    0.002916       0.833333                 0.834821   \n",
      "9  0.001300    0.002919       0.900000                 0.901786   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.866667          0.865460      0.888393  SVM-linear-scale-1  \n",
      "1              0.833333          0.829221      0.800905  SVM-linear-scale-1  \n",
      "2              0.800000          0.798214      0.866071  SVM-linear-scale-1  \n",
      "3              0.700000          0.699666      0.822222  SVM-linear-scale-1  \n",
      "4              0.700000          0.696970      0.804444  SVM-linear-scale-1  \n",
      "5              0.900000          0.900111      0.848214    SVM-poly-scale-1  \n",
      "6              0.800000          0.800893      0.832579    SVM-poly-scale-1  \n",
      "7              0.900000          0.900111      0.924107    SVM-poly-scale-1  \n",
      "8              0.833333          0.833148      0.853333    SVM-poly-scale-1  \n",
      "9              0.900000          0.899889      0.960000    SVM-poly-scale-1  \n",
      "SVM-rbf-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      1.00      0.92        23\n",
      "      benign       1.00      0.85      0.92        27\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.93      0.92        50\n",
      "weighted avg       0.93      0.92      0.92        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.866667          0.865460      0.888393  SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905  SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071  SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444  SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214    SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579    SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107    SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333    SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000    SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714     SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502     SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643     SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333     SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667     SVM-rbf-scale-1  \n",
      "SVM-sigmoid-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.50      0.57      0.53        23\n",
      "      benign       0.58      0.52      0.55        27\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.54      0.54      0.54        50\n",
      "weighted avg       0.55      0.54      0.54        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.73      0.83      0.78        23\n",
      "      benign       0.83      0.74      0.78        27\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.78      0.78        50\n",
      "weighted avg       0.79      0.78      0.78        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "20  0.005021    0.002882       0.866667                 0.872222   \n",
      "21  0.004648    0.002907       0.833333                 0.843333   \n",
      "22  0.002931    0.002892       0.800000                 0.825926   \n",
      "23  0.003835    0.002848       0.700000                 0.700893   \n",
      "24  0.004271    0.002872       0.700000                 0.708333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n",
      "20              0.866667          0.865460      0.888393    SVM-linear-auto-1  \n",
      "21              0.833333          0.829221      0.800905    SVM-linear-auto-1  \n",
      "22              0.800000          0.798214      0.866071    SVM-linear-auto-1  \n",
      "23              0.700000          0.699666      0.822222    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.804444    SVM-linear-auto-1  \n",
      "SVM-poly-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.80      0.87      0.83        23\n",
      "      benign       0.88      0.81      0.85        27\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.84      0.84      0.84        50\n",
      "weighted avg       0.84      0.84      0.84        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "20  0.005021    0.002882       0.866667                 0.872222   \n",
      "21  0.004648    0.002907       0.833333                 0.843333   \n",
      "22  0.002931    0.002892       0.800000                 0.825926   \n",
      "23  0.003835    0.002848       0.700000                 0.700893   \n",
      "24  0.004271    0.002872       0.700000                 0.708333   \n",
      "25  0.002654    0.004173       0.866667                 0.874405   \n",
      "26  0.001846    0.003758       0.833333                 0.836310   \n",
      "27  0.001154    0.002993       0.833333                 0.835556   \n",
      "28  0.001368    0.003026       0.666667                 0.679426   \n",
      "29  0.001413    0.002869       0.733333                 0.777778   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n",
      "20              0.866667          0.865460      0.888393    SVM-linear-auto-1  \n",
      "21              0.833333          0.829221      0.800905    SVM-linear-auto-1  \n",
      "22              0.800000          0.798214      0.866071    SVM-linear-auto-1  \n",
      "23              0.700000          0.699666      0.822222    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.804444    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.857143      SVM-poly-auto-1  \n",
      "26              0.833333          0.833895      0.837104      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.861607      SVM-poly-auto-1  \n",
      "28              0.666667          0.660633      0.693333      SVM-poly-auto-1  \n",
      "29              0.733333          0.722222      0.786667      SVM-poly-auto-1  \n",
      "SVM-rbf-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.47      1.00      0.64        23\n",
      "      benign       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.73      0.52      0.36        50\n",
      "weighted avg       0.76      0.48      0.33        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "20  0.005021    0.002882       0.866667                 0.872222   \n",
      "21  0.004648    0.002907       0.833333                 0.843333   \n",
      "22  0.002931    0.002892       0.800000                 0.825926   \n",
      "23  0.003835    0.002848       0.700000                 0.700893   \n",
      "24  0.004271    0.002872       0.700000                 0.708333   \n",
      "25  0.002654    0.004173       0.866667                 0.874405   \n",
      "26  0.001846    0.003758       0.833333                 0.836310   \n",
      "27  0.001154    0.002993       0.833333                 0.835556   \n",
      "28  0.001368    0.003026       0.666667                 0.679426   \n",
      "29  0.001413    0.002869       0.733333                 0.777778   \n",
      "30  0.001916    0.003510       0.533333                 0.284444   \n",
      "31  0.001431    0.003573       0.566667                 0.321111   \n",
      "32  0.001547    0.003461       0.466667                 0.217778   \n",
      "33  0.001535    0.003511       0.500000                 0.250000   \n",
      "34  0.001533    0.003453       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n",
      "20              0.866667          0.865460      0.888393    SVM-linear-auto-1  \n",
      "21              0.833333          0.829221      0.800905    SVM-linear-auto-1  \n",
      "22              0.800000          0.798214      0.866071    SVM-linear-auto-1  \n",
      "23              0.700000          0.699666      0.822222    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.804444    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.857143      SVM-poly-auto-1  \n",
      "26              0.833333          0.833895      0.837104      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.861607      SVM-poly-auto-1  \n",
      "28              0.666667          0.660633      0.693333      SVM-poly-auto-1  \n",
      "29              0.733333          0.722222      0.786667      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.564732       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.533333       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "SVM-sigmoid-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.46      1.00      0.63        23\n",
      "      benign       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.23      0.50      0.32        50\n",
      "weighted avg       0.21      0.46      0.29        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "20  0.005021    0.002882       0.866667                 0.872222   \n",
      "21  0.004648    0.002907       0.833333                 0.843333   \n",
      "22  0.002931    0.002892       0.800000                 0.825926   \n",
      "23  0.003835    0.002848       0.700000                 0.700893   \n",
      "24  0.004271    0.002872       0.700000                 0.708333   \n",
      "25  0.002654    0.004173       0.866667                 0.874405   \n",
      "26  0.001846    0.003758       0.833333                 0.836310   \n",
      "27  0.001154    0.002993       0.833333                 0.835556   \n",
      "28  0.001368    0.003026       0.666667                 0.679426   \n",
      "29  0.001413    0.002869       0.733333                 0.777778   \n",
      "30  0.001916    0.003510       0.533333                 0.284444   \n",
      "31  0.001431    0.003573       0.566667                 0.321111   \n",
      "32  0.001547    0.003461       0.466667                 0.217778   \n",
      "33  0.001535    0.003511       0.500000                 0.250000   \n",
      "34  0.001533    0.003453       0.500000                 0.250000   \n",
      "35  0.001676    0.003142       0.533333                 0.284444   \n",
      "36  0.001232    0.003120       0.433333                 0.187778   \n",
      "37  0.001172    0.003091       0.466667                 0.217778   \n",
      "38  0.001182    0.003094       0.500000                 0.250000   \n",
      "39  0.001178    0.003238       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n",
      "20              0.866667          0.865460      0.888393    SVM-linear-auto-1  \n",
      "21              0.833333          0.829221      0.800905    SVM-linear-auto-1  \n",
      "22              0.800000          0.798214      0.866071    SVM-linear-auto-1  \n",
      "23              0.700000          0.699666      0.822222    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.804444    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.857143      SVM-poly-auto-1  \n",
      "26              0.833333          0.833895      0.837104      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.861607      SVM-poly-auto-1  \n",
      "28              0.666667          0.660633      0.693333      SVM-poly-auto-1  \n",
      "29              0.733333          0.722222      0.786667      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.564732       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.533333       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "SVM-linear-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.73      0.83      0.78        23\n",
      "      benign       0.83      0.74      0.78        27\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.78      0.78        50\n",
      "weighted avg       0.79      0.78      0.78        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "20  0.005021    0.002882       0.866667                 0.872222   \n",
      "21  0.004648    0.002907       0.833333                 0.843333   \n",
      "22  0.002931    0.002892       0.800000                 0.825926   \n",
      "23  0.003835    0.002848       0.700000                 0.700893   \n",
      "24  0.004271    0.002872       0.700000                 0.708333   \n",
      "25  0.002654    0.004173       0.866667                 0.874405   \n",
      "26  0.001846    0.003758       0.833333                 0.836310   \n",
      "27  0.001154    0.002993       0.833333                 0.835556   \n",
      "28  0.001368    0.003026       0.666667                 0.679426   \n",
      "29  0.001413    0.002869       0.733333                 0.777778   \n",
      "30  0.001916    0.003510       0.533333                 0.284444   \n",
      "31  0.001431    0.003573       0.566667                 0.321111   \n",
      "32  0.001547    0.003461       0.466667                 0.217778   \n",
      "33  0.001535    0.003511       0.500000                 0.250000   \n",
      "34  0.001533    0.003453       0.500000                 0.250000   \n",
      "35  0.001676    0.003142       0.533333                 0.284444   \n",
      "36  0.001232    0.003120       0.433333                 0.187778   \n",
      "37  0.001172    0.003091       0.466667                 0.217778   \n",
      "38  0.001182    0.003094       0.500000                 0.250000   \n",
      "39  0.001178    0.003238       0.500000                 0.250000   \n",
      "40  0.004709    0.002973       0.866667                 0.872222   \n",
      "41  0.004744    0.002973       0.833333                 0.843333   \n",
      "42  0.003048    0.002910       0.800000                 0.825926   \n",
      "43  0.003927    0.002812       0.700000                 0.700893   \n",
      "44  0.004245    0.002801       0.700000                 0.708333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n",
      "20              0.866667          0.865460      0.888393    SVM-linear-auto-1  \n",
      "21              0.833333          0.829221      0.800905    SVM-linear-auto-1  \n",
      "22              0.800000          0.798214      0.866071    SVM-linear-auto-1  \n",
      "23              0.700000          0.699666      0.822222    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.804444    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.857143      SVM-poly-auto-1  \n",
      "26              0.833333          0.833895      0.837104      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.861607      SVM-poly-auto-1  \n",
      "28              0.666667          0.660633      0.693333      SVM-poly-auto-1  \n",
      "29              0.733333          0.722222      0.786667      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.564732       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.533333       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.866667          0.865460      0.888393   SVM-linear-scale-2  \n",
      "41              0.833333          0.829221      0.800905   SVM-linear-scale-2  \n",
      "42              0.800000          0.798214      0.866071   SVM-linear-scale-2  \n",
      "43              0.700000          0.699666      0.822222   SVM-linear-scale-2  \n",
      "44              0.700000          0.696970      0.804444   SVM-linear-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-poly-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.88      1.00      0.94        23\n",
      "      benign       1.00      0.89      0.94        27\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.94      0.94      0.94        50\n",
      "weighted avg       0.95      0.94      0.94        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "20  0.005021    0.002882       0.866667                 0.872222   \n",
      "21  0.004648    0.002907       0.833333                 0.843333   \n",
      "22  0.002931    0.002892       0.800000                 0.825926   \n",
      "23  0.003835    0.002848       0.700000                 0.700893   \n",
      "24  0.004271    0.002872       0.700000                 0.708333   \n",
      "25  0.002654    0.004173       0.866667                 0.874405   \n",
      "26  0.001846    0.003758       0.833333                 0.836310   \n",
      "27  0.001154    0.002993       0.833333                 0.835556   \n",
      "28  0.001368    0.003026       0.666667                 0.679426   \n",
      "29  0.001413    0.002869       0.733333                 0.777778   \n",
      "30  0.001916    0.003510       0.533333                 0.284444   \n",
      "31  0.001431    0.003573       0.566667                 0.321111   \n",
      "32  0.001547    0.003461       0.466667                 0.217778   \n",
      "33  0.001535    0.003511       0.500000                 0.250000   \n",
      "34  0.001533    0.003453       0.500000                 0.250000   \n",
      "35  0.001676    0.003142       0.533333                 0.284444   \n",
      "36  0.001232    0.003120       0.433333                 0.187778   \n",
      "37  0.001172    0.003091       0.466667                 0.217778   \n",
      "38  0.001182    0.003094       0.500000                 0.250000   \n",
      "39  0.001178    0.003238       0.500000                 0.250000   \n",
      "40  0.004709    0.002973       0.866667                 0.872222   \n",
      "41  0.004744    0.002973       0.833333                 0.843333   \n",
      "42  0.003048    0.002910       0.800000                 0.825926   \n",
      "43  0.003927    0.002812       0.700000                 0.700893   \n",
      "44  0.004245    0.002801       0.700000                 0.708333   \n",
      "45  0.001573    0.003008       0.900000                 0.902222   \n",
      "46  0.001395    0.002877       0.800000                 0.808889   \n",
      "47  0.001247    0.004275       0.866667                 0.866667   \n",
      "48  0.001651    0.002985       0.800000                 0.800000   \n",
      "49  0.001349    0.002877       0.866667                 0.873303   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n",
      "20              0.866667          0.865460      0.888393    SVM-linear-auto-1  \n",
      "21              0.833333          0.829221      0.800905    SVM-linear-auto-1  \n",
      "22              0.800000          0.798214      0.866071    SVM-linear-auto-1  \n",
      "23              0.700000          0.699666      0.822222    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.804444    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.857143      SVM-poly-auto-1  \n",
      "26              0.833333          0.833895      0.837104      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.861607      SVM-poly-auto-1  \n",
      "28              0.666667          0.660633      0.693333      SVM-poly-auto-1  \n",
      "29              0.733333          0.722222      0.786667      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.564732       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.533333       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.866667          0.865460      0.888393   SVM-linear-scale-2  \n",
      "41              0.833333          0.829221      0.800905   SVM-linear-scale-2  \n",
      "42              0.800000          0.798214      0.866071   SVM-linear-scale-2  \n",
      "43              0.700000          0.699666      0.822222   SVM-linear-scale-2  \n",
      "44              0.700000          0.696970      0.804444   SVM-linear-scale-2  \n",
      "45              0.900000          0.900111      0.857143     SVM-poly-scale-2  \n",
      "46              0.800000          0.800893      0.809955     SVM-poly-scale-2  \n",
      "47              0.866667          0.866667      0.915179     SVM-poly-scale-2  \n",
      "48              0.800000          0.800000      0.853333     SVM-poly-scale-2  \n",
      "49              0.866667          0.866071      0.960000     SVM-poly-scale-2  \n",
      "SVM-rbf-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.88      1.00      0.94        23\n",
      "      benign       1.00      0.89      0.94        27\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.94      0.94      0.94        50\n",
      "weighted avg       0.95      0.94      0.94        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "20  0.005021    0.002882       0.866667                 0.872222   \n",
      "21  0.004648    0.002907       0.833333                 0.843333   \n",
      "22  0.002931    0.002892       0.800000                 0.825926   \n",
      "23  0.003835    0.002848       0.700000                 0.700893   \n",
      "24  0.004271    0.002872       0.700000                 0.708333   \n",
      "25  0.002654    0.004173       0.866667                 0.874405   \n",
      "26  0.001846    0.003758       0.833333                 0.836310   \n",
      "27  0.001154    0.002993       0.833333                 0.835556   \n",
      "28  0.001368    0.003026       0.666667                 0.679426   \n",
      "29  0.001413    0.002869       0.733333                 0.777778   \n",
      "30  0.001916    0.003510       0.533333                 0.284444   \n",
      "31  0.001431    0.003573       0.566667                 0.321111   \n",
      "32  0.001547    0.003461       0.466667                 0.217778   \n",
      "33  0.001535    0.003511       0.500000                 0.250000   \n",
      "34  0.001533    0.003453       0.500000                 0.250000   \n",
      "35  0.001676    0.003142       0.533333                 0.284444   \n",
      "36  0.001232    0.003120       0.433333                 0.187778   \n",
      "37  0.001172    0.003091       0.466667                 0.217778   \n",
      "38  0.001182    0.003094       0.500000                 0.250000   \n",
      "39  0.001178    0.003238       0.500000                 0.250000   \n",
      "40  0.004709    0.002973       0.866667                 0.872222   \n",
      "41  0.004744    0.002973       0.833333                 0.843333   \n",
      "42  0.003048    0.002910       0.800000                 0.825926   \n",
      "43  0.003927    0.002812       0.700000                 0.700893   \n",
      "44  0.004245    0.002801       0.700000                 0.708333   \n",
      "45  0.001573    0.003008       0.900000                 0.902222   \n",
      "46  0.001395    0.002877       0.800000                 0.808889   \n",
      "47  0.001247    0.004275       0.866667                 0.866667   \n",
      "48  0.001651    0.002985       0.800000                 0.800000   \n",
      "49  0.001349    0.002877       0.866667                 0.873303   \n",
      "50  0.001576    0.003120       0.900000                 0.902222   \n",
      "51  0.001112    0.003206       0.833333                 0.836310   \n",
      "52  0.001181    0.003138       0.833333                 0.835556   \n",
      "53  0.001009    0.003056       0.800000                 0.805430   \n",
      "54  0.001119    0.003115       0.933333                 0.933333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n",
      "20              0.866667          0.865460      0.888393    SVM-linear-auto-1  \n",
      "21              0.833333          0.829221      0.800905    SVM-linear-auto-1  \n",
      "22              0.800000          0.798214      0.866071    SVM-linear-auto-1  \n",
      "23              0.700000          0.699666      0.822222    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.804444    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.857143      SVM-poly-auto-1  \n",
      "26              0.833333          0.833895      0.837104      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.861607      SVM-poly-auto-1  \n",
      "28              0.666667          0.660633      0.693333      SVM-poly-auto-1  \n",
      "29              0.733333          0.722222      0.786667      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.564732       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.533333       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.866667          0.865460      0.888393   SVM-linear-scale-2  \n",
      "41              0.833333          0.829221      0.800905   SVM-linear-scale-2  \n",
      "42              0.800000          0.798214      0.866071   SVM-linear-scale-2  \n",
      "43              0.700000          0.699666      0.822222   SVM-linear-scale-2  \n",
      "44              0.700000          0.696970      0.804444   SVM-linear-scale-2  \n",
      "45              0.900000          0.900111      0.857143     SVM-poly-scale-2  \n",
      "46              0.800000          0.800893      0.809955     SVM-poly-scale-2  \n",
      "47              0.866667          0.866667      0.915179     SVM-poly-scale-2  \n",
      "48              0.800000          0.800000      0.853333     SVM-poly-scale-2  \n",
      "49              0.866667          0.866071      0.960000     SVM-poly-scale-2  \n",
      "50              0.900000          0.900111      0.910714      SVM-rbf-scale-2  \n",
      "51              0.833333          0.833895      0.918552      SVM-rbf-scale-2  \n",
      "52              0.833333          0.833519      0.919643      SVM-rbf-scale-2  \n",
      "53              0.800000          0.799107      0.893333      SVM-rbf-scale-2  \n",
      "54              0.933333          0.933333      0.991111      SVM-rbf-scale-2  \n",
      "SVM-sigmoid-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.71      0.87      0.78        23\n",
      "      benign       0.86      0.70      0.78        27\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.79      0.79      0.78        50\n",
      "weighted avg       0.79      0.78      0.78        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "5   0.001550    0.002923       0.900000                 0.902222   \n",
      "6   0.001356    0.002928       0.800000                 0.808889   \n",
      "7   0.001301    0.002926       0.900000                 0.902222   \n",
      "8   0.001295    0.002916       0.833333                 0.834821   \n",
      "9   0.001300    0.002919       0.900000                 0.901786   \n",
      "10  0.001675    0.003253       0.900000                 0.902222   \n",
      "11  0.001128    0.003138       0.800000                 0.800000   \n",
      "12  0.001145    0.003160       0.866667                 0.866667   \n",
      "13  0.001051    0.003124       0.733333                 0.733333   \n",
      "14  0.001134    0.003165       0.933333                 0.933333   \n",
      "15  0.002145    0.003294       0.533333                 0.529630   \n",
      "16  0.001958    0.003250       0.433333                 0.445833   \n",
      "17  0.002066    0.003260       0.433333                 0.438915   \n",
      "18  0.001946    0.003303       0.600000                 0.601810   \n",
      "19  0.001996    0.003305       0.566667                 0.569444   \n",
      "20  0.005021    0.002882       0.866667                 0.872222   \n",
      "21  0.004648    0.002907       0.833333                 0.843333   \n",
      "22  0.002931    0.002892       0.800000                 0.825926   \n",
      "23  0.003835    0.002848       0.700000                 0.700893   \n",
      "24  0.004271    0.002872       0.700000                 0.708333   \n",
      "25  0.002654    0.004173       0.866667                 0.874405   \n",
      "26  0.001846    0.003758       0.833333                 0.836310   \n",
      "27  0.001154    0.002993       0.833333                 0.835556   \n",
      "28  0.001368    0.003026       0.666667                 0.679426   \n",
      "29  0.001413    0.002869       0.733333                 0.777778   \n",
      "30  0.001916    0.003510       0.533333                 0.284444   \n",
      "31  0.001431    0.003573       0.566667                 0.321111   \n",
      "32  0.001547    0.003461       0.466667                 0.217778   \n",
      "33  0.001535    0.003511       0.500000                 0.250000   \n",
      "34  0.001533    0.003453       0.500000                 0.250000   \n",
      "35  0.001676    0.003142       0.533333                 0.284444   \n",
      "36  0.001232    0.003120       0.433333                 0.187778   \n",
      "37  0.001172    0.003091       0.466667                 0.217778   \n",
      "38  0.001182    0.003094       0.500000                 0.250000   \n",
      "39  0.001178    0.003238       0.500000                 0.250000   \n",
      "40  0.004709    0.002973       0.866667                 0.872222   \n",
      "41  0.004744    0.002973       0.833333                 0.843333   \n",
      "42  0.003048    0.002910       0.800000                 0.825926   \n",
      "43  0.003927    0.002812       0.700000                 0.700893   \n",
      "44  0.004245    0.002801       0.700000                 0.708333   \n",
      "45  0.001573    0.003008       0.900000                 0.902222   \n",
      "46  0.001395    0.002877       0.800000                 0.808889   \n",
      "47  0.001247    0.004275       0.866667                 0.866667   \n",
      "48  0.001651    0.002985       0.800000                 0.800000   \n",
      "49  0.001349    0.002877       0.866667                 0.873303   \n",
      "50  0.001576    0.003120       0.900000                 0.902222   \n",
      "51  0.001112    0.003206       0.833333                 0.836310   \n",
      "52  0.001181    0.003138       0.833333                 0.835556   \n",
      "53  0.001009    0.003056       0.800000                 0.805430   \n",
      "54  0.001119    0.003115       0.933333                 0.933333   \n",
      "55  0.001931    0.003211       0.500000                 0.492823   \n",
      "56  0.002033    0.003159       0.433333                 0.445833   \n",
      "57  0.001161    0.003025       0.900000                 0.902222   \n",
      "58  0.001876    0.003202       0.600000                 0.600000   \n",
      "59  0.002025    0.003202       0.533333                 0.533937   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.866667          0.865460      0.888393   SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905   SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071   SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222   SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.848214     SVM-poly-scale-1  \n",
      "6               0.800000          0.800893      0.832579     SVM-poly-scale-1  \n",
      "7               0.900000          0.900111      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.853333     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.960000     SVM-poly-scale-1  \n",
      "10              0.900000          0.900111      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.909502      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.733333          0.733333      0.893333      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.533333          0.529110      0.544643  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.435224      0.371041  SVM-sigmoid-scale-1  \n",
      "17              0.433333          0.423793      0.321429  SVM-sigmoid-scale-1  \n",
      "18              0.600000          0.598214      0.595556  SVM-sigmoid-scale-1  \n",
      "19              0.566667          0.562290      0.591111  SVM-sigmoid-scale-1  \n",
      "20              0.866667          0.865460      0.888393    SVM-linear-auto-1  \n",
      "21              0.833333          0.829221      0.800905    SVM-linear-auto-1  \n",
      "22              0.800000          0.798214      0.866071    SVM-linear-auto-1  \n",
      "23              0.700000          0.699666      0.822222    SVM-linear-auto-1  \n",
      "24              0.700000          0.696970      0.804444    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.857143      SVM-poly-auto-1  \n",
      "26              0.833333          0.833895      0.837104      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.861607      SVM-poly-auto-1  \n",
      "28              0.666667          0.660633      0.693333      SVM-poly-auto-1  \n",
      "29              0.733333          0.722222      0.786667      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.564732       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.533333       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.866667          0.865460      0.888393   SVM-linear-scale-2  \n",
      "41              0.833333          0.829221      0.800905   SVM-linear-scale-2  \n",
      "42              0.800000          0.798214      0.866071   SVM-linear-scale-2  \n",
      "43              0.700000          0.699666      0.822222   SVM-linear-scale-2  \n",
      "44              0.700000          0.696970      0.804444   SVM-linear-scale-2  \n",
      "45              0.900000          0.900111      0.857143     SVM-poly-scale-2  \n",
      "46              0.800000          0.800893      0.809955     SVM-poly-scale-2  \n",
      "47              0.866667          0.866667      0.915179     SVM-poly-scale-2  \n",
      "48              0.800000          0.800000      0.853333     SVM-poly-scale-2  \n",
      "49              0.866667          0.866071      0.960000     SVM-poly-scale-2  \n",
      "50              0.900000          0.900111      0.910714      SVM-rbf-scale-2  \n",
      "51              0.833333          0.833895      0.918552      SVM-rbf-scale-2  \n",
      "52              0.833333          0.833519      0.919643      SVM-rbf-scale-2  \n",
      "53              0.800000          0.799107      0.893333      SVM-rbf-scale-2  \n",
      "54              0.933333          0.933333      0.991111      SVM-rbf-scale-2  \n",
      "55              0.500000          0.491429      0.517857  SVM-sigmoid-scale-2  \n",
      "56              0.433333          0.435224      0.343891  SVM-sigmoid-scale-2  \n",
      "57              0.900000          0.900111      0.892857  SVM-sigmoid-scale-2  \n",
      "58              0.600000          0.600000      0.564444  SVM-sigmoid-scale-2  \n",
      "59              0.533333          0.531250      0.560000  SVM-sigmoid-scale-2  \n",
      "SVM-linear-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.73      0.83      0.78        23\n",
      "      benign       0.83      0.74      0.78        27\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.78      0.78        50\n",
      "weighted avg       0.79      0.78      0.78        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "..       ...         ...            ...                      ...   \n",
      "60  0.004973    0.002849       0.866667                 0.872222   \n",
      "61  0.004599    0.002857       0.833333                 0.843333   \n",
      "62  0.002802    0.002859       0.800000                 0.825926   \n",
      "63  0.003801    0.002910       0.700000                 0.700893   \n",
      "64  0.004188    0.002831       0.700000                 0.708333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.866667          0.865460      0.888393  SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905  SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071  SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "60              0.866667          0.865460      0.888393   SVM-linear-auto-2  \n",
      "61              0.833333          0.829221      0.800905   SVM-linear-auto-2  \n",
      "62              0.800000          0.798214      0.866071   SVM-linear-auto-2  \n",
      "63              0.700000          0.699666      0.822222   SVM-linear-auto-2  \n",
      "64              0.700000          0.696970      0.804444   SVM-linear-auto-2  \n",
      "\n",
      "[65 rows x 8 columns]\n",
      "SVM-poly-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.80      0.87      0.83        23\n",
      "      benign       0.88      0.81      0.85        27\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.84      0.84      0.84        50\n",
      "weighted avg       0.84      0.84      0.84        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "..       ...         ...            ...                      ...   \n",
      "65  0.001794    0.002969       0.866667                 0.874405   \n",
      "66  0.001383    0.002840       0.833333                 0.836310   \n",
      "67  0.001029    0.002821       0.833333                 0.835556   \n",
      "68  0.001306    0.002835       0.666667                 0.679426   \n",
      "69  0.001388    0.002856       0.733333                 0.777778   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.866667          0.865460      0.888393  SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905  SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071  SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "65              0.866667          0.866667      0.857143     SVM-poly-auto-2  \n",
      "66              0.833333          0.833895      0.837104     SVM-poly-auto-2  \n",
      "67              0.833333          0.833519      0.861607     SVM-poly-auto-2  \n",
      "68              0.666667          0.660633      0.693333     SVM-poly-auto-2  \n",
      "69              0.733333          0.722222      0.786667     SVM-poly-auto-2  \n",
      "\n",
      "[70 rows x 8 columns]\n",
      "SVM-rbf-auto-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.47      1.00      0.64        23\n",
      "      benign       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.73      0.52      0.36        50\n",
      "weighted avg       0.76      0.48      0.33        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "..       ...         ...            ...                      ...   \n",
      "70  0.001853    0.003545       0.533333                 0.284444   \n",
      "71  0.001464    0.003568       0.566667                 0.321111   \n",
      "72  0.001693    0.003449       0.466667                 0.217778   \n",
      "73  0.001626    0.003449       0.500000                 0.250000   \n",
      "74  0.001644    0.003463       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.866667          0.865460      0.888393  SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905  SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071  SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "70              0.533333          0.371014      0.564732      SVM-rbf-auto-2  \n",
      "71              0.566667          0.409929      0.558824      SVM-rbf-auto-2  \n",
      "72              0.466667          0.296970      0.531250      SVM-rbf-auto-2  \n",
      "73              0.500000          0.333333      0.533333      SVM-rbf-auto-2  \n",
      "74              0.500000          0.333333      0.500000      SVM-rbf-auto-2  \n",
      "\n",
      "[75 rows x 8 columns]\n",
      "SVM-sigmoid-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.46      1.00      0.63        23\n",
      "      benign       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.23      0.50      0.32        50\n",
      "weighted avg       0.21      0.46      0.29        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004958    0.003295       0.866667                 0.872222   \n",
      "1   0.004817    0.002979       0.833333                 0.843333   \n",
      "2   0.002984    0.002905       0.800000                 0.825926   \n",
      "3   0.003961    0.002876       0.700000                 0.700893   \n",
      "4   0.004283    0.002876       0.700000                 0.708333   \n",
      "..       ...         ...            ...                      ...   \n",
      "75  0.001415    0.003100       0.533333                 0.284444   \n",
      "76  0.001205    0.003147       0.433333                 0.187778   \n",
      "77  0.001171    0.003057       0.466667                 0.217778   \n",
      "78  0.001190    0.003066       0.500000                 0.250000   \n",
      "79  0.001194    0.003065       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.866667          0.865460      0.888393  SVM-linear-scale-1  \n",
      "1               0.833333          0.829221      0.800905  SVM-linear-scale-1  \n",
      "2               0.800000          0.798214      0.866071  SVM-linear-scale-1  \n",
      "3               0.700000          0.699666      0.822222  SVM-linear-scale-1  \n",
      "4               0.700000          0.696970      0.804444  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "75              0.533333          0.371014      0.500000  SVM-sigmoid-auto-2  \n",
      "76              0.433333          0.262016      0.500000  SVM-sigmoid-auto-2  \n",
      "77              0.466667          0.296970      0.500000  SVM-sigmoid-auto-2  \n",
      "78              0.500000          0.333333      0.500000  SVM-sigmoid-auto-2  \n",
      "79              0.500000          0.333333      0.500000  SVM-sigmoid-auto-2  \n",
      "\n",
      "[80 rows x 8 columns]\n",
      "3.175036564000038\n"
     ]
    }
   ],
   "source": [
    "## S0: All Combined \n",
    " \n",
    "df_malicious = pd.concat([df1,df2,df3,df4,df5,df6,df7,df32,df33,df34,df35])[:1000]\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df11,df10,df12,df13,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df30,df27,df29])[:1000]\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2ccaca2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1217322\n",
      "benign: 1212624\n",
      "0 NAN in malicious!\n",
      "28 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1217322\n",
      "benign: 1212596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [03:04<00:00,  1.15s/it]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [03:10<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.98      0.98     30381\n",
      "      benign       0.98      0.99      0.98     30368\n",
      "\n",
      "    accuracy                           0.98     60749\n",
      "   macro avg       0.98      0.98      0.98     60749\n",
      "weighted avg       0.98      0.98      0.98     60749\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  3.917238    0.098114       0.984883                 0.984938   \n",
      "1  3.803594    0.096094       0.983127                 0.983171   \n",
      "2  3.726536    0.094469       0.983566                 0.983611   \n",
      "3  3.847533    0.108561       0.983374                 0.983425   \n",
      "4  4.421095    0.096820       0.985267                 0.985305   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.984883          0.984883      0.994859  LogReg  \n",
      "1              0.983127          0.983126      0.994138  LogReg  \n",
      "2              0.983566          0.983565      0.995323  LogReg  \n",
      "3              0.983374          0.983374      0.995031  LogReg  \n",
      "4              0.985267          0.985266      0.995785  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.99      0.99     30381\n",
      "      benign       0.99      0.99      0.99     30368\n",
      "\n",
      "    accuracy                           0.99     60749\n",
      "   macro avg       0.99      0.99      0.99     60749\n",
      "weighted avg       0.99      0.99      0.99     60749\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  3.917238    0.098114       0.984883                 0.984938   \n",
      "1  3.803594    0.096094       0.983127                 0.983171   \n",
      "2  3.726536    0.094469       0.983566                 0.983611   \n",
      "3  3.847533    0.108561       0.983374                 0.983425   \n",
      "4  4.421095    0.096820       0.985267                 0.985305   \n",
      "5  0.213591  227.951482       0.990178                 0.990201   \n",
      "6  0.258487  241.122932       0.988395                 0.988413   \n",
      "7  0.292842  229.348359       0.989574                 0.989593   \n",
      "8  0.285844  236.663778       0.989437                 0.989453   \n",
      "9  0.263027  240.945271       0.990864                 0.990881   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.984883          0.984883      0.994859  LogReg  \n",
      "1              0.983127          0.983126      0.994138  LogReg  \n",
      "2              0.983566          0.983565      0.995323  LogReg  \n",
      "3              0.983374          0.983374      0.995031  LogReg  \n",
      "4              0.985267          0.985266      0.995785  LogReg  \n",
      "5              0.990178          0.990178      0.995282     KNN  \n",
      "6              0.988395          0.988394      0.995188     KNN  \n",
      "7              0.989574          0.989574      0.995877     KNN  \n",
      "8              0.989437          0.989437      0.995655     KNN  \n",
      "9              0.990864          0.990864      0.996055     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.98      0.99     30381\n",
      "      benign       0.98      0.99      0.99     30368\n",
      "\n",
      "    accuracy                           0.99     60749\n",
      "   macro avg       0.99      0.99      0.99     60749\n",
      "weighted avg       0.99      0.99      0.99     60749\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     3.917238    0.098114       0.984883                 0.984938   \n",
      "1     3.803594    0.096094       0.983127                 0.983171   \n",
      "2     3.726536    0.094469       0.983566                 0.983611   \n",
      "3     3.847533    0.108561       0.983374                 0.983425   \n",
      "4     4.421095    0.096820       0.985267                 0.985305   \n",
      "5     0.213591  227.951482       0.990178                 0.990201   \n",
      "6     0.258487  241.122932       0.988395                 0.988413   \n",
      "7     0.292842  229.348359       0.989574                 0.989593   \n",
      "8     0.285844  236.663778       0.989437                 0.989453   \n",
      "9     0.263027  240.945271       0.990864                 0.990881   \n",
      "10  403.337641  151.928011       0.988395                 0.988468   \n",
      "11  389.133749  166.761042       0.987380                 0.987462   \n",
      "12  487.881185  180.328360       0.988669                 0.988742   \n",
      "13  530.955066  186.020072       0.987873                 0.987946   \n",
      "14  780.418004  120.451481       0.988669                 0.988753   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.984883          0.984883      0.994859  LogReg  \n",
      "1               0.983127          0.983126      0.994138  LogReg  \n",
      "2               0.983566          0.983565      0.995323  LogReg  \n",
      "3               0.983374          0.983374      0.995031  LogReg  \n",
      "4               0.985267          0.985266      0.995785  LogReg  \n",
      "5               0.990178          0.990178      0.995282     KNN  \n",
      "6               0.988395          0.988394      0.995188     KNN  \n",
      "7               0.989574          0.989574      0.995877     KNN  \n",
      "8               0.989437          0.989437      0.995655     KNN  \n",
      "9               0.990864          0.990864      0.996055     KNN  \n",
      "10              0.988395          0.988395      0.996706     SVM  \n",
      "11              0.987380          0.987378      0.995716     SVM  \n",
      "12              0.988669          0.988668      0.997051     SVM  \n",
      "13              0.987873          0.987873      0.996610     SVM  \n",
      "14              0.988669          0.988668      0.997344     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.99      0.99     30381\n",
      "      benign       0.99      1.00      0.99     30368\n",
      "\n",
      "    accuracy                           0.99     60749\n",
      "   macro avg       0.99      0.99      0.99     60749\n",
      "weighted avg       0.99      0.99      0.99     60749\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     3.917238    0.098114       0.984883                 0.984938   \n",
      "1     3.803594    0.096094       0.983127                 0.983171   \n",
      "2     3.726536    0.094469       0.983566                 0.983611   \n",
      "3     3.847533    0.108561       0.983374                 0.983425   \n",
      "4     4.421095    0.096820       0.985267                 0.985305   \n",
      "5     0.213591  227.951482       0.990178                 0.990201   \n",
      "6     0.258487  241.122932       0.988395                 0.988413   \n",
      "7     0.292842  229.348359       0.989574                 0.989593   \n",
      "8     0.285844  236.663778       0.989437                 0.989453   \n",
      "9     0.263027  240.945271       0.990864                 0.990881   \n",
      "10  403.337641  151.928011       0.988395                 0.988468   \n",
      "11  389.133749  166.761042       0.987380                 0.987462   \n",
      "12  487.881185  180.328360       0.988669                 0.988742   \n",
      "13  530.955066  186.020072       0.987873                 0.987946   \n",
      "14  780.418004  120.451481       0.988669                 0.988753   \n",
      "15    0.976246    0.407110       0.995171                 0.995189   \n",
      "16    0.878297    0.405632       0.994979                 0.995001   \n",
      "17    0.880213    0.405632       0.995336                 0.995351   \n",
      "18    0.879158    0.407845       0.995089                 0.995117   \n",
      "19    0.889425    0.413945       0.995939                 0.995950   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.984883          0.984883      0.994859  LogReg  \n",
      "1               0.983127          0.983126      0.994138  LogReg  \n",
      "2               0.983566          0.983565      0.995323  LogReg  \n",
      "3               0.983374          0.983374      0.995031  LogReg  \n",
      "4               0.985267          0.985266      0.995785  LogReg  \n",
      "5               0.990178          0.990178      0.995282     KNN  \n",
      "6               0.988395          0.988394      0.995188     KNN  \n",
      "7               0.989574          0.989574      0.995877     KNN  \n",
      "8               0.989437          0.989437      0.995655     KNN  \n",
      "9               0.990864          0.990864      0.996055     KNN  \n",
      "10              0.988395          0.988395      0.996706     SVM  \n",
      "11              0.987380          0.987378      0.995716     SVM  \n",
      "12              0.988669          0.988668      0.997051     SVM  \n",
      "13              0.987873          0.987873      0.996610     SVM  \n",
      "14              0.988669          0.988668      0.997344     SVM  \n",
      "15              0.995171          0.995171      0.995389     GNB  \n",
      "16              0.994979          0.994979      0.995124     GNB  \n",
      "17              0.995336          0.995336      0.995393     GNB  \n",
      "18              0.995089          0.995089      0.995195     GNB  \n",
      "19              0.995939          0.995939      0.996041     GNB  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7137.976874612999\n"
     ]
    }
   ],
   "source": [
    "#scenario 1 :Devices\n",
    "# 1) Server\n",
    " \n",
    "df_malicious = pd.concat([df2,df7,df32])\n",
    "df_benign = pd.concat([df10,df11,df13,df15,df16,df17,df18,df19,df21,df22,df23,df26,df30,df28])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_server_s1 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "28fe3dfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 234272\n",
      "benign: 234460\n",
      "0 NAN in malicious!\n",
      "12 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 234272\n",
      "benign: 234448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:37<00:00,  4.28it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:36<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98      5800\n",
      "      benign       0.98      0.98      0.98      5919\n",
      "\n",
      "    accuracy                           0.98     11719\n",
      "   macro avg       0.98      0.98      0.98     11719\n",
      "weighted avg       0.98      0.98      0.98     11719\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.075405    0.024079       0.979377                 0.979387   \n",
      "1  1.364292    0.023713       0.980515                 0.980523   \n",
      "2  1.586039    0.038076       0.981937                 0.981951   \n",
      "3  1.331024    0.021471       0.976959                 0.976986   \n",
      "4  1.438708    0.036448       0.978236                 0.978237   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.979377          0.979377      0.998213  LogReg  \n",
      "1              0.980515          0.980515      0.998428  LogReg  \n",
      "2              0.981937          0.981937      0.998969  LogReg  \n",
      "3              0.976959          0.976957      0.998201  LogReg  \n",
      "4              0.978236          0.978236      0.998476  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.97      0.97      5800\n",
      "      benign       0.97      0.97      0.97      5919\n",
      "\n",
      "    accuracy                           0.97     11719\n",
      "   macro avg       0.97      0.97      0.97     11719\n",
      "weighted avg       0.97      0.97      0.97     11719\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.075405    0.024079       0.979377                 0.979387   \n",
      "1  1.364292    0.023713       0.980515                 0.980523   \n",
      "2  1.586039    0.038076       0.981937                 0.981951   \n",
      "3  1.331024    0.021471       0.976959                 0.976986   \n",
      "4  1.438708    0.036448       0.978236                 0.978237   \n",
      "5  0.041965    8.019634       0.975679                 0.975680   \n",
      "6  0.040650    8.627798       0.973119                 0.973146   \n",
      "7  0.037719    8.144911       0.970274                 0.970275   \n",
      "8  0.037200    8.250002       0.969706                 0.969719   \n",
      "9  0.035903    7.843922       0.970128                 0.970161   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.979377          0.979377      0.998213  LogReg  \n",
      "1              0.980515          0.980515      0.998428  LogReg  \n",
      "2              0.981937          0.981937      0.998969  LogReg  \n",
      "3              0.976959          0.976957      0.998201  LogReg  \n",
      "4              0.978236          0.978236      0.998476  LogReg  \n",
      "5              0.975679          0.975679      0.993801     KNN  \n",
      "6              0.973119          0.973120      0.992792     KNN  \n",
      "7              0.970274          0.970274      0.993409     KNN  \n",
      "8              0.969706          0.969704      0.991904     KNN  \n",
      "9              0.970128          0.970131      0.992281     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98      5800\n",
      "      benign       0.98      0.98      0.98      5919\n",
      "\n",
      "    accuracy                           0.98     11719\n",
      "   macro avg       0.98      0.98      0.98     11719\n",
      "weighted avg       0.98      0.98      0.98     11719\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.075405    0.024079       0.979377                 0.979387   \n",
      "1    1.364292    0.023713       0.980515                 0.980523   \n",
      "2    1.586039    0.038076       0.981937                 0.981951   \n",
      "3    1.331024    0.021471       0.976959                 0.976986   \n",
      "4    1.438708    0.036448       0.978236                 0.978237   \n",
      "5    0.041965    8.019634       0.975679                 0.975680   \n",
      "6    0.040650    8.627798       0.973119                 0.973146   \n",
      "7    0.037719    8.144911       0.970274                 0.970275   \n",
      "8    0.037200    8.250002       0.969706                 0.969719   \n",
      "9    0.035903    7.843922       0.970128                 0.970161   \n",
      "10  18.848208    8.670635       0.983075                 0.983076   \n",
      "11  19.244485    8.924814       0.984213                 0.984214   \n",
      "12  18.471443    8.745067       0.982079                 0.982087   \n",
      "13  18.595964    8.393545       0.982648                 0.982673   \n",
      "14  18.261225    8.477569       0.980939                 0.980962   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.979377          0.979377      0.998213  LogReg  \n",
      "1               0.980515          0.980515      0.998428  LogReg  \n",
      "2               0.981937          0.981937      0.998969  LogReg  \n",
      "3               0.976959          0.976957      0.998201  LogReg  \n",
      "4               0.978236          0.978236      0.998476  LogReg  \n",
      "5               0.975679          0.975679      0.993801     KNN  \n",
      "6               0.973119          0.973120      0.992792     KNN  \n",
      "7               0.970274          0.970274      0.993409     KNN  \n",
      "8               0.969706          0.969704      0.991904     KNN  \n",
      "9               0.970128          0.970131      0.992281     KNN  \n",
      "10              0.983075          0.983075      0.995877     SVM  \n",
      "11              0.984213          0.984213      0.997576     SVM  \n",
      "12              0.982079          0.982079      0.996905     SVM  \n",
      "13              0.982648          0.982647      0.997139     SVM  \n",
      "14              0.980939          0.980941      0.996085     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00      5800\n",
      "      benign       1.00      1.00      1.00      5919\n",
      "\n",
      "    accuracy                           1.00     11719\n",
      "   macro avg       1.00      1.00      1.00     11719\n",
      "weighted avg       1.00      1.00      1.00     11719\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.075405    0.024079       0.979377                 0.979387   \n",
      "1    1.364292    0.023713       0.980515                 0.980523   \n",
      "2    1.586039    0.038076       0.981937                 0.981951   \n",
      "3    1.331024    0.021471       0.976959                 0.976986   \n",
      "4    1.438708    0.036448       0.978236                 0.978237   \n",
      "5    0.041965    8.019634       0.975679                 0.975680   \n",
      "6    0.040650    8.627798       0.973119                 0.973146   \n",
      "7    0.037719    8.144911       0.970274                 0.970275   \n",
      "8    0.037200    8.250002       0.969706                 0.969719   \n",
      "9    0.035903    7.843922       0.970128                 0.970161   \n",
      "10  18.848208    8.670635       0.983075                 0.983076   \n",
      "11  19.244485    8.924814       0.984213                 0.984214   \n",
      "12  18.471443    8.745067       0.982079                 0.982087   \n",
      "13  18.595964    8.393545       0.982648                 0.982673   \n",
      "14  18.261225    8.477569       0.980939                 0.980962   \n",
      "15   0.121859    0.044467       1.000000                 1.000000   \n",
      "16   0.120729    0.042709       0.999716                 0.999716   \n",
      "17   0.119048    0.048394       0.999858                 0.999858   \n",
      "18   0.120137    0.041507       1.000000                 1.000000   \n",
      "19   0.119677    0.041821       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.979377          0.979377      0.998213  LogReg  \n",
      "1               0.980515          0.980515      0.998428  LogReg  \n",
      "2               0.981937          0.981937      0.998969  LogReg  \n",
      "3               0.976959          0.976957      0.998201  LogReg  \n",
      "4               0.978236          0.978236      0.998476  LogReg  \n",
      "5               0.975679          0.975679      0.993801     KNN  \n",
      "6               0.973119          0.973120      0.992792     KNN  \n",
      "7               0.970274          0.970274      0.993409     KNN  \n",
      "8               0.969706          0.969704      0.991904     KNN  \n",
      "9               0.970128          0.970131      0.992281     KNN  \n",
      "10              0.983075          0.983075      0.995877     SVM  \n",
      "11              0.984213          0.984213      0.997576     SVM  \n",
      "12              0.982079          0.982079      0.996905     SVM  \n",
      "13              0.982648          0.982647      0.997139     SVM  \n",
      "14              0.980939          0.980941      0.996085     SVM  \n",
      "15              1.000000          1.000000      1.000000     GNB  \n",
      "16              0.999716          0.999716      0.999711     GNB  \n",
      "17              0.999858          0.999858      0.999858     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              1.000000          1.000000      1.000000     GNB  \n",
      "387.5566537749837\n"
     ]
    }
   ],
   "source": [
    " #2) Laptop\n",
    "df_malicious = pd.concat([df35])\n",
    "df_benign = pd.concat([df8,df20,df19,df30])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Laptop_s1 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb1291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 60545\n",
      "benign: 62594\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 60545\n",
      "benign: 62594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:10<00:00, 14.65it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 157/157 [00:10<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n"
     ]
    }
   ],
   "source": [
    "#3) IoT\n",
    "\n",
    "df_malicious = pd.concat([df4,df5,df6,df33,df34])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df15,df16,df17,df21])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Raspberry_s1 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0029dbfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 9880\n",
      "benign: 9877\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 9880\n",
      "benign: 9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 142/142 [00:02<00:00, 57.16it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 142/142 [00:03<00:00, 45.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.94      0.94       246\n",
      "      benign       0.94      0.95      0.95       248\n",
      "\n",
      "    accuracy                           0.95       494\n",
      "   macro avg       0.95      0.95      0.95       494\n",
      "weighted avg       0.95      0.95      0.95       494\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  2.149490    0.025123       0.946128                 0.946370   \n",
      "1  2.106410    0.024873       0.929293                 0.929521   \n",
      "2  1.992329    0.022448       0.922297                 0.922481   \n",
      "3  2.070526    0.024539       0.918919                 0.920032   \n",
      "4  2.010084    0.028977       0.932432                 0.932872   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.946128          0.946076      0.981756  LogReg  \n",
      "1              0.929293          0.929312      0.976433  LogReg  \n",
      "2              0.922297          0.922295      0.967721  LogReg  \n",
      "3              0.918919          0.918800      0.977111  LogReg  \n",
      "4              0.932432          0.932482      0.983352  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.89      0.93      0.91       246\n",
      "      benign       0.92      0.88      0.90       248\n",
      "\n",
      "    accuracy                           0.90       494\n",
      "   macro avg       0.91      0.90      0.90       494\n",
      "weighted avg       0.91      0.90      0.90       494\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  2.149490    0.025123       0.946128                 0.946370   \n",
      "1  2.106410    0.024873       0.929293                 0.929521   \n",
      "2  1.992329    0.022448       0.922297                 0.922481   \n",
      "3  2.070526    0.024539       0.918919                 0.920032   \n",
      "4  2.010084    0.028977       0.932432                 0.932872   \n",
      "5  0.002548    0.129716       0.898990                 0.899125   \n",
      "6  0.013734    0.110155       0.898990                 0.902239   \n",
      "7  0.013690    0.113376       0.898649                 0.902187   \n",
      "8  0.013814    0.108723       0.902027                 0.902063   \n",
      "9  0.013720    0.110766       0.925676                 0.927191   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.946128          0.946076      0.981756  LogReg  \n",
      "1              0.929293          0.929312      0.976433  LogReg  \n",
      "2              0.922297          0.922295      0.967721  LogReg  \n",
      "3              0.918919          0.918800      0.977111  LogReg  \n",
      "4              0.932432          0.932482      0.983352  LogReg  \n",
      "5              0.898990          0.898893      0.960601     KNN  \n",
      "6              0.898990          0.898586      0.953751     KNN  \n",
      "7              0.898649          0.898389      0.968886     KNN  \n",
      "8              0.902027          0.902035      0.960618     KNN  \n",
      "9              0.925676          0.925757      0.968951     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.92      0.91      0.91       246\n",
      "      benign       0.91      0.92      0.92       248\n",
      "\n",
      "    accuracy                           0.91       494\n",
      "   macro avg       0.92      0.91      0.91       494\n",
      "weighted avg       0.92      0.91      0.91       494\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   2.149490    0.025123       0.946128                 0.946370   \n",
      "1   2.106410    0.024873       0.929293                 0.929521   \n",
      "2   1.992329    0.022448       0.922297                 0.922481   \n",
      "3   2.070526    0.024539       0.918919                 0.920032   \n",
      "4   2.010084    0.028977       0.932432                 0.932872   \n",
      "5   0.002548    0.129716       0.898990                 0.899125   \n",
      "6   0.013734    0.110155       0.898990                 0.902239   \n",
      "7   0.013690    0.113376       0.898649                 0.902187   \n",
      "8   0.013814    0.108723       0.902027                 0.902063   \n",
      "9   0.013720    0.110766       0.925676                 0.927191   \n",
      "10  0.086445    0.064985       0.909091                 0.909074   \n",
      "11  0.076233    0.070466       0.902357                 0.902448   \n",
      "12  0.081925    0.075589       0.939189                 0.939189   \n",
      "13  0.079425    0.075281       0.881757                 0.881849   \n",
      "14  0.079255    0.069825       0.922297                 0.922957   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.946128          0.946076      0.981756  LogReg  \n",
      "1               0.929293          0.929312      0.976433  LogReg  \n",
      "2               0.922297          0.922295      0.967721  LogReg  \n",
      "3               0.918919          0.918800      0.977111  LogReg  \n",
      "4               0.932432          0.932482      0.983352  LogReg  \n",
      "5               0.898990          0.898893      0.960601     KNN  \n",
      "6               0.898990          0.898586      0.953751     KNN  \n",
      "7               0.898649          0.898389      0.968886     KNN  \n",
      "8               0.902027          0.902035      0.960618     KNN  \n",
      "9               0.925676          0.925757      0.968951     KNN  \n",
      "10              0.909091          0.909072      0.971383     SVM  \n",
      "11              0.902357          0.902310      0.974071     SVM  \n",
      "12              0.939189          0.939189      0.983518     SVM  \n",
      "13              0.881757          0.881712      0.963907     SVM  \n",
      "14              0.922297          0.922364      0.983948     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.99      1.00       246\n",
      "      benign       0.99      1.00      1.00       248\n",
      "\n",
      "    accuracy                           1.00       494\n",
      "   macro avg       1.00      1.00      1.00       494\n",
      "weighted avg       1.00      1.00      1.00       494\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   2.149490    0.025123       0.946128                 0.946370   \n",
      "1   2.106410    0.024873       0.929293                 0.929521   \n",
      "2   1.992329    0.022448       0.922297                 0.922481   \n",
      "3   2.070526    0.024539       0.918919                 0.920032   \n",
      "4   2.010084    0.028977       0.932432                 0.932872   \n",
      "5   0.002548    0.129716       0.898990                 0.899125   \n",
      "6   0.013734    0.110155       0.898990                 0.902239   \n",
      "7   0.013690    0.113376       0.898649                 0.902187   \n",
      "8   0.013814    0.108723       0.902027                 0.902063   \n",
      "9   0.013720    0.110766       0.925676                 0.927191   \n",
      "10  0.086445    0.064985       0.909091                 0.909074   \n",
      "11  0.076233    0.070466       0.902357                 0.902448   \n",
      "12  0.081925    0.075589       0.939189                 0.939189   \n",
      "13  0.079425    0.075281       0.881757                 0.881849   \n",
      "14  0.079255    0.069825       0.922297                 0.922957   \n",
      "15  0.004969    0.005522       1.000000                 1.000000   \n",
      "16  0.003756    0.005292       1.000000                 1.000000   \n",
      "17  0.003548    0.005319       1.000000                 1.000000   \n",
      "18  0.003652    0.005286       1.000000                 1.000000   \n",
      "19  0.003677    0.005359       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.946128          0.946076      0.981756  LogReg  \n",
      "1               0.929293          0.929312      0.976433  LogReg  \n",
      "2               0.922297          0.922295      0.967721  LogReg  \n",
      "3               0.918919          0.918800      0.977111  LogReg  \n",
      "4               0.932432          0.932482      0.983352  LogReg  \n",
      "5               0.898990          0.898893      0.960601     KNN  \n",
      "6               0.898990          0.898586      0.953751     KNN  \n",
      "7               0.898649          0.898389      0.968886     KNN  \n",
      "8               0.902027          0.902035      0.960618     KNN  \n",
      "9               0.925676          0.925757      0.968951     KNN  \n",
      "10              0.909091          0.909072      0.971383     SVM  \n",
      "11              0.902357          0.902310      0.974071     SVM  \n",
      "12              0.939189          0.939189      0.983518     SVM  \n",
      "13              0.881757          0.881712      0.963907     SVM  \n",
      "14              0.922297          0.922364      0.983948     SVM  \n",
      "15              1.000000          1.000000      1.000000     GNB  \n",
      "16              1.000000          1.000000      1.000000     GNB  \n",
      "17              1.000000          1.000000      1.000000     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              1.000000          1.000000      1.000000     GNB  \n",
      "29.746887399989646\n"
     ]
    }
   ],
   "source": [
    "# Scenario 2; Throttles\n",
    "    \n",
    "    # 1) THR: %10 (Stealthy)\n",
    "\n",
    "df_malicious = pd.concat([df33])\n",
    "df_benign = pd.concat([df8,df10])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_10_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e8bff47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 9925\n",
      "benign: 10453\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 9925\n",
      "benign: 10453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 142/142 [00:02<00:00, 70.03it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 150/150 [00:02<00:00, 72.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "SVM-linear-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00       264\n",
      "      benign       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.159152    0.008241            1.0                      1.0   \n",
      "1  0.066759    0.007451            1.0                      1.0   \n",
      "2  0.166499    0.007725            1.0                      1.0   \n",
      "3  0.162189    0.006943            1.0                      1.0   \n",
      "4  0.108057    0.007698            1.0                      1.0   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "1                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "2                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "3                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "4                   1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "SVM-poly-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.86      0.81      0.83       264\n",
      "      benign       0.81      0.86      0.83       246\n",
      "\n",
      "    accuracy                           0.83       510\n",
      "   macro avg       0.83      0.83      0.83       510\n",
      "weighted avg       0.83      0.83      0.83       510\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.159152    0.008241       1.000000                 1.000000   \n",
      "1  0.066759    0.007451       1.000000                 1.000000   \n",
      "2  0.166499    0.007725       1.000000                 1.000000   \n",
      "3  0.162189    0.006943       1.000000                 1.000000   \n",
      "4  0.108057    0.007698       1.000000                 1.000000   \n",
      "5  0.093857    0.032366       0.803922                 0.804398   \n",
      "6  0.092993    0.033614       0.823529                 0.825977   \n",
      "7  0.093297    0.035702       0.830065                 0.838691   \n",
      "8  0.091128    0.032552       0.800654                 0.800726   \n",
      "9  0.094834    0.033950       0.822951                 0.832710   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "1              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "2              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "3              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "4              1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "5              0.803922          0.804022      0.873806    SVM-poly-scale-1  \n",
      "6              0.823529          0.823484      0.911692    SVM-poly-scale-1  \n",
      "7              0.830065          0.830065      0.917554    SVM-poly-scale-1  \n",
      "8              0.800654          0.800681      0.868236    SVM-poly-scale-1  \n",
      "9              0.822951          0.821705      0.920795    SVM-poly-scale-1  \n",
      "SVM-rbf-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.80      0.90      0.85       264\n",
      "      benign       0.88      0.76      0.81       246\n",
      "\n",
      "    accuracy                           0.83       510\n",
      "   macro avg       0.84      0.83      0.83       510\n",
      "weighted avg       0.84      0.83      0.83       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806    SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692    SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554    SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236    SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795    SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413     SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889     SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905     SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366     SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140     SVM-rbf-scale-1  \n",
      "SVM-sigmoid-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.74      0.72      0.73       264\n",
      "      benign       0.70      0.72      0.71       246\n",
      "\n",
      "    accuracy                           0.72       510\n",
      "   macro avg       0.72      0.72      0.72       510\n",
      "weighted avg       0.72      0.72      0.72       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00       264\n",
      "      benign       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "SVM-poly-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.89      0.89      0.89       264\n",
      "      benign       0.88      0.88      0.88       246\n",
      "\n",
      "    accuracy                           0.88       510\n",
      "   macro avg       0.88      0.88      0.88       510\n",
      "weighted avg       0.88      0.88      0.88       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.61      1.00      0.75       264\n",
      "      benign       1.00      0.30      0.46       246\n",
      "\n",
      "    accuracy                           0.66       510\n",
      "   macro avg       0.80      0.65      0.61       510\n",
      "weighted avg       0.80      0.66      0.61       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "SVM-sigmoid-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.52      1.00      0.68       264\n",
      "      benign       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.52       510\n",
      "   macro avg       0.26      0.50      0.34       510\n",
      "weighted avg       0.27      0.52      0.35       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00       264\n",
      "      benign       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "40  0.158930    0.008091       1.000000                 1.000000   \n",
      "41  0.067559    0.007482       1.000000                 1.000000   \n",
      "42  0.166358    0.007492       1.000000                 1.000000   \n",
      "43  0.161433    0.006910       1.000000                 1.000000   \n",
      "44  0.107317    0.007662       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n",
      "40              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "41              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "42              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "43              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "44              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "SVM-poly-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.86      0.83      0.85       264\n",
      "      benign       0.83      0.85      0.84       246\n",
      "\n",
      "    accuracy                           0.84       510\n",
      "   macro avg       0.84      0.84      0.84       510\n",
      "weighted avg       0.84      0.84      0.84       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "40  0.158930    0.008091       1.000000                 1.000000   \n",
      "41  0.067559    0.007482       1.000000                 1.000000   \n",
      "42  0.166358    0.007492       1.000000                 1.000000   \n",
      "43  0.161433    0.006910       1.000000                 1.000000   \n",
      "44  0.107317    0.007662       1.000000                 1.000000   \n",
      "45  0.094209    0.028626       0.823529                 0.823992   \n",
      "46  0.094393    0.030249       0.866013                 0.866068   \n",
      "47  0.094275    0.030231       0.869281                 0.870219   \n",
      "48  0.092161    0.028752       0.823529                 0.824836   \n",
      "49  0.094198    0.030057       0.826230                 0.830396   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n",
      "40              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "41              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "42              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "43              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "44              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "45              0.823529          0.823620      0.882030     SVM-poly-scale-2  \n",
      "46              0.866013          0.865957      0.920587     SVM-poly-scale-2  \n",
      "47              0.869281          0.869415      0.924854     SVM-poly-scale-2  \n",
      "48              0.823529          0.823620      0.870933     SVM-poly-scale-2  \n",
      "49              0.826230          0.825720      0.924450     SVM-poly-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.86      0.91      0.88       264\n",
      "      benign       0.89      0.84      0.87       246\n",
      "\n",
      "    accuracy                           0.87       510\n",
      "   macro avg       0.88      0.87      0.87       510\n",
      "weighted avg       0.88      0.87      0.87       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "40  0.158930    0.008091       1.000000                 1.000000   \n",
      "41  0.067559    0.007482       1.000000                 1.000000   \n",
      "42  0.166358    0.007492       1.000000                 1.000000   \n",
      "43  0.161433    0.006910       1.000000                 1.000000   \n",
      "44  0.107317    0.007662       1.000000                 1.000000   \n",
      "45  0.094209    0.028626       0.823529                 0.823992   \n",
      "46  0.094393    0.030249       0.866013                 0.866068   \n",
      "47  0.094275    0.030231       0.869281                 0.870219   \n",
      "48  0.092161    0.028752       0.823529                 0.824836   \n",
      "49  0.094198    0.030057       0.826230                 0.830396   \n",
      "50  0.083215    0.077581       0.820261                 0.821257   \n",
      "51  0.086975    0.085261       0.846405                 0.855171   \n",
      "52  0.089320    0.085370       0.882353                 0.882965   \n",
      "53  0.085426    0.083856       0.826797                 0.834103   \n",
      "54  0.086171    0.085961       0.862295                 0.862363   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n",
      "40              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "41              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "42              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "43              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "44              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "45              0.823529          0.823620      0.882030     SVM-poly-scale-2  \n",
      "46              0.866013          0.865957      0.920587     SVM-poly-scale-2  \n",
      "47              0.869281          0.869415      0.924854     SVM-poly-scale-2  \n",
      "48              0.823529          0.823620      0.870933     SVM-poly-scale-2  \n",
      "49              0.826230          0.825720      0.924450     SVM-poly-scale-2  \n",
      "50              0.820261          0.819687      0.879203      SVM-rbf-scale-2  \n",
      "51              0.846405          0.844951      0.922297      SVM-rbf-scale-2  \n",
      "52              0.882353          0.882048      0.924468      SVM-rbf-scale-2  \n",
      "53              0.826797          0.826525      0.888271      SVM-rbf-scale-2  \n",
      "54              0.862295          0.862292      0.928148      SVM-rbf-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-sigmoid-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.75      0.71      0.73       264\n",
      "      benign       0.71      0.74      0.72       246\n",
      "\n",
      "    accuracy                           0.73       510\n",
      "   macro avg       0.73      0.73      0.73       510\n",
      "weighted avg       0.73      0.73      0.73       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "5   0.093857    0.032366       0.803922                 0.804398   \n",
      "6   0.092993    0.033614       0.823529                 0.825977   \n",
      "7   0.093297    0.035702       0.830065                 0.838691   \n",
      "8   0.091128    0.032552       0.800654                 0.800726   \n",
      "9   0.094834    0.033950       0.822951                 0.832710   \n",
      "10  0.085961    0.089645       0.777778                 0.779646   \n",
      "11  0.089390    0.094593       0.826797                 0.832337   \n",
      "12  0.089846    0.088340       0.833333                 0.839362   \n",
      "13  0.088910    0.089758       0.803922                 0.814384   \n",
      "14  0.090306    0.088924       0.826230                 0.827895   \n",
      "15  0.064985    0.030488       0.643791                 0.643675   \n",
      "16  0.064678    0.032200       0.686275                 0.686172   \n",
      "17  0.066070    0.031633       0.728758                 0.728339   \n",
      "18  0.144057    0.066356       0.330065                 0.331079   \n",
      "19  0.067822    0.032284       0.731148                 0.732203   \n",
      "20  0.156396    0.007900       1.000000                 1.000000   \n",
      "21  0.067388    0.007515       1.000000                 1.000000   \n",
      "22  0.165808    0.007370       1.000000                 1.000000   \n",
      "23  0.161933    0.006891       1.000000                 1.000000   \n",
      "24  0.107602    0.007654       1.000000                 1.000000   \n",
      "25  0.122665    0.016166       0.882353                 0.883085   \n",
      "26  0.115771    0.016057       0.921569                 0.921924   \n",
      "27  0.137284    0.016568       0.928105                 0.928566   \n",
      "28  0.139052    0.015475       0.872549                 0.872527   \n",
      "29  0.110767    0.015370       0.885246                 0.889044   \n",
      "30  0.138970    0.145343       0.568627                 0.742467   \n",
      "31  0.132746    0.140131       0.637255                 0.786938   \n",
      "32  0.131117    0.146591       0.627451                 0.793352   \n",
      "33  0.136956    0.144377       0.575163                 0.744714   \n",
      "34  0.135907    0.145289       0.613115                 0.781574   \n",
      "35  0.133119    0.057754       0.526144                 0.276827   \n",
      "36  0.132212    0.056665       0.516340                 0.266607   \n",
      "37  0.134041    0.057149       0.535948                 0.287240   \n",
      "38  0.130327    0.055601       0.477124                 0.227647   \n",
      "39  0.131748    0.056124       0.501639                 0.251642   \n",
      "40  0.158930    0.008091       1.000000                 1.000000   \n",
      "41  0.067559    0.007482       1.000000                 1.000000   \n",
      "42  0.166358    0.007492       1.000000                 1.000000   \n",
      "43  0.161433    0.006910       1.000000                 1.000000   \n",
      "44  0.107317    0.007662       1.000000                 1.000000   \n",
      "45  0.094209    0.028626       0.823529                 0.823992   \n",
      "46  0.094393    0.030249       0.866013                 0.866068   \n",
      "47  0.094275    0.030231       0.869281                 0.870219   \n",
      "48  0.092161    0.028752       0.823529                 0.824836   \n",
      "49  0.094198    0.030057       0.826230                 0.830396   \n",
      "50  0.083215    0.077581       0.820261                 0.821257   \n",
      "51  0.086975    0.085261       0.846405                 0.855171   \n",
      "52  0.089320    0.085370       0.882353                 0.882965   \n",
      "53  0.085426    0.083856       0.826797                 0.834103   \n",
      "54  0.086171    0.085961       0.862295                 0.862363   \n",
      "55  0.062519    0.029204       0.643791                 0.643675   \n",
      "56  0.062473    0.030022       0.686275                 0.686275   \n",
      "57  0.064480    0.030670       0.732026                 0.731647   \n",
      "58  0.139167    0.063171       0.333333                 0.334282   \n",
      "59  0.065073    0.030984       0.731148                 0.732203   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000   SVM-linear-scale-1  \n",
      "5               0.803922          0.804022      0.873806     SVM-poly-scale-1  \n",
      "6               0.823529          0.823484      0.911692     SVM-poly-scale-1  \n",
      "7               0.830065          0.830065      0.917554     SVM-poly-scale-1  \n",
      "8               0.800654          0.800681      0.868236     SVM-poly-scale-1  \n",
      "9               0.822951          0.821705      0.920795     SVM-poly-scale-1  \n",
      "10              0.777778          0.776549      0.859413      SVM-rbf-scale-1  \n",
      "11              0.826797          0.825581      0.899889      SVM-rbf-scale-1  \n",
      "12              0.833333          0.831450      0.906905      SVM-rbf-scale-1  \n",
      "13              0.803922          0.803267      0.879366      SVM-rbf-scale-1  \n",
      "14              0.826230          0.825983      0.917140      SVM-rbf-scale-1  \n",
      "15              0.643791          0.643726      0.681988  SVM-sigmoid-scale-1  \n",
      "16              0.686275          0.686194      0.703344  SVM-sigmoid-scale-1  \n",
      "17              0.728758          0.728165      0.782162  SVM-sigmoid-scale-1  \n",
      "18              0.330065          0.329013      0.333776  SVM-sigmoid-scale-1  \n",
      "19              0.731148          0.730887      0.766469  SVM-sigmoid-scale-1  \n",
      "20              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "21              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "22              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "23              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "24              1.000000          1.000000      1.000000    SVM-linear-auto-1  \n",
      "25              0.882353          0.882110      0.930735      SVM-poly-auto-1  \n",
      "26              0.921569          0.921589      0.970450      SVM-poly-auto-1  \n",
      "27              0.928105          0.927974      0.967923      SVM-poly-auto-1  \n",
      "28              0.872549          0.872529      0.905437      SVM-poly-auto-1  \n",
      "29              0.885246          0.884986      0.937393      SVM-poly-auto-1  \n",
      "30              0.568627          0.492366      0.698179       SVM-rbf-auto-1  \n",
      "31              0.637255          0.575580      0.719723       SVM-rbf-auto-1  \n",
      "32              0.627451          0.581576      0.740746       SVM-rbf-auto-1  \n",
      "33              0.575163          0.501231      0.696747       SVM-rbf-auto-1  \n",
      "34              0.613115          0.544229      0.705689       SVM-rbf-auto-1  \n",
      "35              0.526144          0.362780      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.516340          0.351645      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.535948          0.374023      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.477124          0.308231      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.501639          0.335156      0.500000   SVM-sigmoid-auto-1  \n",
      "40              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "41              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "42              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "43              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "44              1.000000          1.000000      1.000000   SVM-linear-scale-2  \n",
      "45              0.823529          0.823620      0.882030     SVM-poly-scale-2  \n",
      "46              0.866013          0.865957      0.920587     SVM-poly-scale-2  \n",
      "47              0.869281          0.869415      0.924854     SVM-poly-scale-2  \n",
      "48              0.823529          0.823620      0.870933     SVM-poly-scale-2  \n",
      "49              0.826230          0.825720      0.924450     SVM-poly-scale-2  \n",
      "50              0.820261          0.819687      0.879203      SVM-rbf-scale-2  \n",
      "51              0.846405          0.844951      0.922297      SVM-rbf-scale-2  \n",
      "52              0.882353          0.882048      0.924468      SVM-rbf-scale-2  \n",
      "53              0.826797          0.826525      0.888271      SVM-rbf-scale-2  \n",
      "54              0.862295          0.862292      0.928148      SVM-rbf-scale-2  \n",
      "55              0.643791          0.643726      0.682116  SVM-sigmoid-scale-2  \n",
      "56              0.686275          0.686275      0.703259  SVM-sigmoid-scale-2  \n",
      "57              0.732026          0.731333      0.782635  SVM-sigmoid-scale-2  \n",
      "58              0.333333          0.332079      0.334675  SVM-sigmoid-scale-2  \n",
      "59              0.731148          0.730887      0.766512  SVM-sigmoid-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00       264\n",
      "      benign       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241            1.0                      1.0   \n",
      "1   0.066759    0.007451            1.0                      1.0   \n",
      "2   0.166499    0.007725            1.0                      1.0   \n",
      "3   0.162189    0.006943            1.0                      1.0   \n",
      "4   0.108057    0.007698            1.0                      1.0   \n",
      "..       ...         ...            ...                      ...   \n",
      "60  0.156528    0.007882            1.0                      1.0   \n",
      "61  0.066907    0.007387            1.0                      1.0   \n",
      "62  0.164653    0.007347            1.0                      1.0   \n",
      "63  0.160970    0.006921            1.0                      1.0   \n",
      "64  0.106825    0.007662            1.0                      1.0   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "1                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "2                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "3                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "4                    1.0               1.0           1.0  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "60                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "61                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "62                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "63                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "64                   1.0               1.0           1.0   SVM-linear-auto-2  \n",
      "\n",
      "[65 rows x 8 columns]\n",
      "SVM-poly-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.89      0.89      0.89       264\n",
      "      benign       0.88      0.88      0.88       246\n",
      "\n",
      "    accuracy                           0.88       510\n",
      "   macro avg       0.88      0.88      0.88       510\n",
      "weighted avg       0.88      0.88      0.88       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "..       ...         ...            ...                      ...   \n",
      "65  0.122201    0.016132       0.882353                 0.883085   \n",
      "66  0.115726    0.016022       0.921569                 0.921924   \n",
      "67  0.136905    0.016429       0.928105                 0.928566   \n",
      "68  0.138379    0.015502       0.872549                 0.872527   \n",
      "69  0.109803    0.015316       0.885246                 0.889044   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "65              0.882353          0.882110      0.930735     SVM-poly-auto-2  \n",
      "66              0.921569          0.921589      0.970450     SVM-poly-auto-2  \n",
      "67              0.928105          0.927974      0.967923     SVM-poly-auto-2  \n",
      "68              0.872549          0.872529      0.905437     SVM-poly-auto-2  \n",
      "69              0.885246          0.884986      0.937393     SVM-poly-auto-2  \n",
      "\n",
      "[70 rows x 8 columns]\n",
      "SVM-rbf-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.61      1.00      0.75       264\n",
      "      benign       1.00      0.30      0.46       246\n",
      "\n",
      "    accuracy                           0.66       510\n",
      "   macro avg       0.80      0.65      0.61       510\n",
      "weighted avg       0.80      0.66      0.61       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "..       ...         ...            ...                      ...   \n",
      "70  0.132862    0.134238       0.568627                 0.742467   \n",
      "71  0.128907    0.139466       0.637255                 0.786938   \n",
      "72  0.132379    0.132263       0.627451                 0.793352   \n",
      "73  0.134615    0.131866       0.575163                 0.744714   \n",
      "74  0.132904    0.130773       0.613115                 0.781574   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "1               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "2               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "3               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "4               1.000000          1.000000      1.000000  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "70              0.568627          0.492366      0.698179      SVM-rbf-auto-2  \n",
      "71              0.637255          0.575580      0.719723      SVM-rbf-auto-2  \n",
      "72              0.627451          0.581576      0.740746      SVM-rbf-auto-2  \n",
      "73              0.575163          0.501231      0.696747      SVM-rbf-auto-2  \n",
      "74              0.613115          0.544229      0.705689      SVM-rbf-auto-2  \n",
      "\n",
      "[75 rows x 8 columns]\n",
      "SVM-sigmoid-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.52      1.00      0.68       264\n",
      "      benign       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.52       510\n",
      "   macro avg       0.26      0.50      0.34       510\n",
      "weighted avg       0.27      0.52      0.35       510\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.159152    0.008241       1.000000                 1.000000   \n",
      "1   0.066759    0.007451       1.000000                 1.000000   \n",
      "2   0.166499    0.007725       1.000000                 1.000000   \n",
      "3   0.162189    0.006943       1.000000                 1.000000   \n",
      "4   0.108057    0.007698       1.000000                 1.000000   \n",
      "..       ...         ...            ...                      ...   \n",
      "75  0.134493    0.057452       0.526144                 0.276827   \n",
      "76  0.131970    0.057287       0.516340                 0.266607   \n",
      "77  0.134505    0.057460       0.535948                 0.287240   \n",
      "78  0.133134    0.056192       0.477124                 0.227647   \n",
      "79  0.132552    0.056562       0.501639                 0.251642   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "1               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "2               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "3               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "4               1.000000          1.000000           1.0  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "75              0.526144          0.362780           0.5  SVM-sigmoid-auto-2  \n",
      "76              0.516340          0.351645           0.5  SVM-sigmoid-auto-2  \n",
      "77              0.535948          0.374023           0.5  SVM-sigmoid-auto-2  \n",
      "78              0.477124          0.308231           0.5  SVM-sigmoid-auto-2  \n",
      "79              0.501639          0.335156           0.5  SVM-sigmoid-auto-2  \n",
      "\n",
      "[80 rows x 8 columns]\n",
      "24.918010805999074\n"
     ]
    }
   ],
   "source": [
    "# 2) THR: %50 (Robust)\n",
    "\n",
    "df_malicious = pd.concat([df3,df34])\n",
    "df_benign = pd.concat([df29,df31])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_50_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2dac9d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1520681\n",
      "benign: 1519195\n",
      "0 NAN in malicious!\n",
      "33 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1520681\n",
      "benign: 1519162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [04:23<00:00,  1.64s/it]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [04:07<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98     37923\n",
      "      benign       0.98      0.98      0.98     38074\n",
      "\n",
      "    accuracy                           0.98     75997\n",
      "   macro avg       0.98      0.98      0.98     75997\n",
      "weighted avg       0.98      0.98      0.98     75997\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  6.241755    0.235247       0.981008                 0.981078   \n",
      "1  6.566289    0.168072       0.979714                 0.979780   \n",
      "2  7.357708    0.129282       0.979363                 0.979428   \n",
      "3  5.899415    0.139058       0.979692                 0.979797   \n",
      "4  5.758039    0.129053       0.979560                 0.979615   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.981008          0.981007      0.992900  LogReg  \n",
      "1              0.979714          0.979713      0.992195  LogReg  \n",
      "2              0.979363          0.979363      0.992892  LogReg  \n",
      "3              0.979692          0.979691      0.992489  LogReg  \n",
      "4              0.979560          0.979559      0.992577  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98     37923\n",
      "      benign       0.98      0.98      0.98     38074\n",
      "\n",
      "    accuracy                           0.98     75997\n",
      "   macro avg       0.98      0.98      0.98     75997\n",
      "weighted avg       0.98      0.98      0.98     75997\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  6.241755    0.235247       0.981008                 0.981078   \n",
      "1  6.566289    0.168072       0.979714                 0.979780   \n",
      "2  7.357708    0.129282       0.979363                 0.979428   \n",
      "3  5.899415    0.139058       0.979692                 0.979797   \n",
      "4  5.758039    0.129053       0.979560                 0.979615   \n",
      "5  0.253100  367.878758       0.979999                 0.980009   \n",
      "6  0.270692  363.608822       0.979889                 0.979900   \n",
      "7  0.254529  363.882532       0.979122                 0.979126   \n",
      "8  0.270708  369.489278       0.978946                 0.978954   \n",
      "9  0.428487  391.086489       0.979100                 0.979105   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.981008          0.981007      0.992900  LogReg  \n",
      "1              0.979714          0.979713      0.992195  LogReg  \n",
      "2              0.979363          0.979363      0.992892  LogReg  \n",
      "3              0.979692          0.979691      0.992489  LogReg  \n",
      "4              0.979560          0.979559      0.992577  LogReg  \n",
      "5              0.979999          0.979999      0.992979     KNN  \n",
      "6              0.979889          0.979889      0.993013     KNN  \n",
      "7              0.979122          0.979122      0.992672     KNN  \n",
      "8              0.978946          0.978946      0.993082     KNN  \n",
      "9              0.979100          0.979099      0.993063     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.98      0.98     37923\n",
      "      benign       0.98      0.99      0.98     38074\n",
      "\n",
      "    accuracy                           0.98     75997\n",
      "   macro avg       0.98      0.98      0.98     75997\n",
      "weighted avg       0.98      0.98      0.98     75997\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      6.241755    0.235247       0.981008                 0.981078   \n",
      "1      6.566289    0.168072       0.979714                 0.979780   \n",
      "2      7.357708    0.129282       0.979363                 0.979428   \n",
      "3      5.899415    0.139058       0.979692                 0.979797   \n",
      "4      5.758039    0.129053       0.979560                 0.979615   \n",
      "5      0.253100  367.878758       0.979999                 0.980009   \n",
      "6      0.270692  363.608822       0.979889                 0.979900   \n",
      "7      0.254529  363.882532       0.979122                 0.979126   \n",
      "8      0.270708  369.489278       0.978946                 0.978954   \n",
      "9      0.428487  391.086489       0.979100                 0.979105   \n",
      "10  1719.707144  270.929915       0.984495                 0.984642   \n",
      "11  1609.793466  265.811531       0.984341                 0.984512   \n",
      "12  2408.418243  272.574108       0.983837                 0.983987   \n",
      "13  2302.584075  261.156202       0.983179                 0.983363   \n",
      "14  2195.438468  260.862245       0.983924                 0.984071   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.981008          0.981007      0.992900  LogReg  \n",
      "1               0.979714          0.979713      0.992195  LogReg  \n",
      "2               0.979363          0.979363      0.992892  LogReg  \n",
      "3               0.979692          0.979691      0.992489  LogReg  \n",
      "4               0.979560          0.979559      0.992577  LogReg  \n",
      "5               0.979999          0.979999      0.992979     KNN  \n",
      "6               0.979889          0.979889      0.993013     KNN  \n",
      "7               0.979122          0.979122      0.992672     KNN  \n",
      "8               0.978946          0.978946      0.993082     KNN  \n",
      "9               0.979100          0.979099      0.993063     KNN  \n",
      "10              0.984495          0.984494      0.996208     SVM  \n",
      "11              0.984341          0.984340      0.995856     SVM  \n",
      "12              0.983837          0.983837      0.995612     SVM  \n",
      "13              0.983179          0.983177      0.996074     SVM  \n",
      "14              0.983924          0.983923      0.995069     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.96      0.98     37923\n",
      "      benign       0.97      1.00      0.98     38074\n",
      "\n",
      "    accuracy                           0.98     75997\n",
      "   macro avg       0.98      0.98      0.98     75997\n",
      "weighted avg       0.98      0.98      0.98     75997\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      6.241755    0.235247       0.981008                 0.981078   \n",
      "1      6.566289    0.168072       0.979714                 0.979780   \n",
      "2      7.357708    0.129282       0.979363                 0.979428   \n",
      "3      5.899415    0.139058       0.979692                 0.979797   \n",
      "4      5.758039    0.129053       0.979560                 0.979615   \n",
      "5      0.253100  367.878758       0.979999                 0.980009   \n",
      "6      0.270692  363.608822       0.979889                 0.979900   \n",
      "7      0.254529  363.882532       0.979122                 0.979126   \n",
      "8      0.270708  369.489278       0.978946                 0.978954   \n",
      "9      0.428487  391.086489       0.979100                 0.979105   \n",
      "10  1719.707144  270.929915       0.984495                 0.984642   \n",
      "11  1609.793466  265.811531       0.984341                 0.984512   \n",
      "12  2408.418243  272.574108       0.983837                 0.983987   \n",
      "13  2302.584075  261.156202       0.983179                 0.983363   \n",
      "14  2195.438468  260.862245       0.983924                 0.984071   \n",
      "15     1.011097    0.467396       0.981622                 0.982154   \n",
      "16     1.015896    0.463127       0.980394                 0.980956   \n",
      "17     1.018739    0.469019       0.980065                 0.980557   \n",
      "18     1.012077    0.464469       0.979582                 0.980147   \n",
      "19     1.011041    0.489543       0.979736                 0.980238   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.981008          0.981007      0.992900  LogReg  \n",
      "1               0.979714          0.979713      0.992195  LogReg  \n",
      "2               0.979363          0.979363      0.992892  LogReg  \n",
      "3               0.979692          0.979691      0.992489  LogReg  \n",
      "4               0.979560          0.979559      0.992577  LogReg  \n",
      "5               0.979999          0.979999      0.992979     KNN  \n",
      "6               0.979889          0.979889      0.993013     KNN  \n",
      "7               0.979122          0.979122      0.992672     KNN  \n",
      "8               0.978946          0.978946      0.993082     KNN  \n",
      "9               0.979100          0.979099      0.993063     KNN  \n",
      "10              0.984495          0.984494      0.996208     SVM  \n",
      "11              0.984341          0.984340      0.995856     SVM  \n",
      "12              0.983837          0.983837      0.995612     SVM  \n",
      "13              0.983179          0.983177      0.996074     SVM  \n",
      "14              0.983924          0.983923      0.995069     SVM  \n",
      "15              0.981622          0.981617      0.982440     GNB  \n",
      "16              0.980394          0.980388      0.981718     GNB  \n",
      "17              0.980065          0.980062      0.982058     GNB  \n",
      "18              0.979582          0.979576      0.981123     GNB  \n",
      "19              0.979736          0.979730      0.981806     GNB  \n",
      "18343.352437399008\n"
     ]
    }
   ],
   "source": [
    " # 3) THR: %100 (Aggressive)\n",
    "    \n",
    "df_malicious = pd.concat([df1,df2,df4,df5,df6,df7,df35])\n",
    "df_benign    = pd.concat([df11,df12,df13,df14,df16,df17,df21,df23,df26,df27,df28,df29,df30,df31])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_100_s2 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "59871271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 305874\n",
      "benign: 305986\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 305874\n",
      "benign: 305986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:46<00:00,  3.47it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:44<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      0.95      0.94      7673\n",
      "      benign       0.95      0.94      0.94      7624\n",
      "\n",
      "    accuracy                           0.94     15297\n",
      "   macro avg       0.94      0.94      0.94     15297\n",
      "weighted avg       0.94      0.94      0.94     15297\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.147231    0.027446       0.946938                 0.946968   \n",
      "1  1.221294    0.027929       0.944541                 0.944582   \n",
      "2  1.332521    0.027896       0.943888                 0.943930   \n",
      "3  1.356204    0.025924       0.944541                 0.944541   \n",
      "4  1.326981    0.026675       0.941055                 0.941064   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.946938          0.946938      0.987825  LogReg  \n",
      "1              0.944541          0.944539      0.986436  LogReg  \n",
      "2              0.943888          0.943882      0.986171  LogReg  \n",
      "3              0.944541          0.944541      0.987119  LogReg  \n",
      "4              0.941055          0.941055      0.986536  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.95      0.95      7673\n",
      "      benign       0.95      0.95      0.95      7624\n",
      "\n",
      "    accuracy                           0.95     15297\n",
      "   macro avg       0.95      0.95      0.95     15297\n",
      "weighted avg       0.95      0.95      0.95     15297\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.147231    0.027446       0.946938                 0.946968   \n",
      "1  1.221294    0.027929       0.944541                 0.944582   \n",
      "2  1.332521    0.027896       0.943888                 0.943930   \n",
      "3  1.356204    0.025924       0.944541                 0.944541   \n",
      "4  1.326981    0.026675       0.941055                 0.941064   \n",
      "5  0.056470   13.989522       0.949880                 0.949880   \n",
      "6  0.060676   14.532398       0.950970                 0.951017   \n",
      "7  0.058871   14.833807       0.947374                 0.947380   \n",
      "8  0.059967   13.639086       0.951514                 0.951515   \n",
      "9  0.057181   13.968773       0.950534                 0.950537   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.946938          0.946938      0.987825  LogReg  \n",
      "1              0.944541          0.944539      0.986436  LogReg  \n",
      "2              0.943888          0.943882      0.986171  LogReg  \n",
      "3              0.944541          0.944541      0.987119  LogReg  \n",
      "4              0.941055          0.941055      0.986536  LogReg  \n",
      "5              0.949880          0.949880      0.982280     KNN  \n",
      "6              0.950970          0.950968      0.982859     KNN  \n",
      "7              0.947374          0.947372      0.981301     KNN  \n",
      "8              0.951514          0.951514      0.982667     KNN  \n",
      "9              0.950534          0.950534      0.983163     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.96      0.96      7673\n",
      "      benign       0.96      0.95      0.95      7624\n",
      "\n",
      "    accuracy                           0.95     15297\n",
      "   macro avg       0.95      0.95      0.95     15297\n",
      "weighted avg       0.95      0.95      0.95     15297\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.147231    0.027446       0.946938                 0.946968   \n",
      "1    1.221294    0.027929       0.944541                 0.944582   \n",
      "2    1.332521    0.027896       0.943888                 0.943930   \n",
      "3    1.356204    0.025924       0.944541                 0.944541   \n",
      "4    1.326981    0.026675       0.941055                 0.941064   \n",
      "5    0.056470   13.989522       0.949880                 0.949880   \n",
      "6    0.060676   14.532398       0.950970                 0.951017   \n",
      "7    0.058871   14.833807       0.947374                 0.947380   \n",
      "8    0.059967   13.639086       0.951514                 0.951515   \n",
      "9    0.057181   13.968773       0.950534                 0.950537   \n",
      "10  63.081430   25.736706       0.959032                 0.959068   \n",
      "11  62.196387   25.654908       0.957616                 0.957706   \n",
      "12  61.949671   25.775296       0.952386                 0.952463   \n",
      "13  62.221753   25.886045       0.955982                 0.955987   \n",
      "14  63.113585   25.931333       0.954783                 0.954870   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.946938          0.946938      0.987825  LogReg  \n",
      "1               0.944541          0.944539      0.986436  LogReg  \n",
      "2               0.943888          0.943882      0.986171  LogReg  \n",
      "3               0.944541          0.944541      0.987119  LogReg  \n",
      "4               0.941055          0.941055      0.986536  LogReg  \n",
      "5               0.949880          0.949880      0.982280     KNN  \n",
      "6               0.950970          0.950968      0.982859     KNN  \n",
      "7               0.947374          0.947372      0.981301     KNN  \n",
      "8               0.951514          0.951514      0.982667     KNN  \n",
      "9               0.950534          0.950534      0.983163     KNN  \n",
      "10              0.959032          0.959032      0.988469     SVM  \n",
      "11              0.957616          0.957613      0.987542     SVM  \n",
      "12              0.952386          0.952380      0.986196     SVM  \n",
      "13              0.955982          0.955983      0.987046     SVM  \n",
      "14              0.954783          0.954782      0.986617     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00      7673\n",
      "      benign       1.00      1.00      1.00      7624\n",
      "\n",
      "    accuracy                           1.00     15297\n",
      "   macro avg       1.00      1.00      1.00     15297\n",
      "weighted avg       1.00      1.00      1.00     15297\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.147231    0.027446       0.946938                 0.946968   \n",
      "1    1.221294    0.027929       0.944541                 0.944582   \n",
      "2    1.332521    0.027896       0.943888                 0.943930   \n",
      "3    1.356204    0.025924       0.944541                 0.944541   \n",
      "4    1.326981    0.026675       0.941055                 0.941064   \n",
      "5    0.056470   13.989522       0.949880                 0.949880   \n",
      "6    0.060676   14.532398       0.950970                 0.951017   \n",
      "7    0.058871   14.833807       0.947374                 0.947380   \n",
      "8    0.059967   13.639086       0.951514                 0.951515   \n",
      "9    0.057181   13.968773       0.950534                 0.950537   \n",
      "10  63.081430   25.736706       0.959032                 0.959068   \n",
      "11  62.196387   25.654908       0.957616                 0.957706   \n",
      "12  61.949671   25.775296       0.952386                 0.952463   \n",
      "13  62.221753   25.886045       0.955982                 0.955987   \n",
      "14  63.113585   25.931333       0.954783                 0.954870   \n",
      "15   0.200196    0.064987       0.999128                 0.999129   \n",
      "16   0.167376    0.055524       0.999346                 0.999347   \n",
      "17   0.182874    0.054627       0.999237                 0.999238   \n",
      "18   0.169218    0.055054       0.999346                 0.999346   \n",
      "19   0.168751    0.055839       0.999455                 0.999456   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.946938          0.946938      0.987825  LogReg  \n",
      "1               0.944541          0.944539      0.986436  LogReg  \n",
      "2               0.943888          0.943882      0.986171  LogReg  \n",
      "3               0.944541          0.944541      0.987119  LogReg  \n",
      "4               0.941055          0.941055      0.986536  LogReg  \n",
      "5               0.949880          0.949880      0.982280     KNN  \n",
      "6               0.950970          0.950968      0.982859     KNN  \n",
      "7               0.947374          0.947372      0.981301     KNN  \n",
      "8               0.951514          0.951514      0.982667     KNN  \n",
      "9               0.950534          0.950534      0.983163     KNN  \n",
      "10              0.959032          0.959032      0.988469     SVM  \n",
      "11              0.957616          0.957613      0.987542     SVM  \n",
      "12              0.952386          0.952380      0.986196     SVM  \n",
      "13              0.955982          0.955983      0.987046     SVM  \n",
      "14              0.954783          0.954782      0.986617     SVM  \n",
      "15              0.999128          0.999128      0.999781     GNB  \n",
      "16              0.999346          0.999346      0.999781     GNB  \n",
      "17              0.999237          0.999237      0.999449     GNB  \n",
      "18              0.999346          0.999346      0.999781     GNB  \n",
      "19              0.999455          0.999455      0.999673     GNB  \n",
      "848.614447156011\n"
     ]
    }
   ],
   "source": [
    "## S3; In-browser VS Binary ##\n",
    "\n",
    "  #1) In-Browser\n",
    "df_malicious = pd.concat([df3,df5,df6,df7,df32,df33,df34,df35])\n",
    "df_benign = pd.concat([df8,df9,df14,df15,df16,df17,df18,df19,df20,df14])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_In_s3 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0d2ca979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1251356\n",
      "benign: 1250262\n",
      "0 NAN in malicious!\n",
      "21 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1251356\n",
      "benign: 1250241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [03:25<00:00,  1.29s/it]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [03:14<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.99      0.99     31333\n",
      "      benign       0.99      0.99      0.99     31208\n",
      "\n",
      "    accuracy                           0.99     62541\n",
      "   macro avg       0.99      0.99      0.99     62541\n",
      "weighted avg       0.99      0.99      0.99     62541\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  5.003206    0.098611       0.988674                 0.988681   \n",
      "1  5.322900    0.099633       0.989260                 0.989272   \n",
      "2  4.944912    0.098912       0.989420                 0.989431   \n",
      "3  5.348714    0.116901       0.989127                 0.989134   \n",
      "4  5.561235    0.107373       0.989393                 0.989399   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.988674          0.988674      0.997320  LogReg  \n",
      "1              0.989260          0.989260      0.997032  LogReg  \n",
      "2              0.989420          0.989420      0.997092  LogReg  \n",
      "3              0.989127          0.989127      0.997198  LogReg  \n",
      "4              0.989393          0.989393      0.997222  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.99      0.99     31333\n",
      "      benign       0.99      0.99      0.99     31208\n",
      "\n",
      "    accuracy                           0.99     62541\n",
      "   macro avg       0.99      0.99      0.99     62541\n",
      "weighted avg       0.99      0.99      0.99     62541\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  5.003206    0.098611       0.988674                 0.988681   \n",
      "1  5.322900    0.099633       0.989260                 0.989272   \n",
      "2  4.944912    0.098912       0.989420                 0.989431   \n",
      "3  5.348714    0.116901       0.989127                 0.989134   \n",
      "4  5.561235    0.107373       0.989393                 0.989399   \n",
      "5  0.196815  244.694879       0.991445                 0.991451   \n",
      "6  0.186335  231.440139       0.991739                 0.991745   \n",
      "7  0.228985  248.913006       0.991765                 0.991776   \n",
      "8  0.351334  248.499317       0.991312                 0.991321   \n",
      "9  0.250481  247.239608       0.991312                 0.991317   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.988674          0.988674      0.997320  LogReg  \n",
      "1              0.989260          0.989260      0.997032  LogReg  \n",
      "2              0.989420          0.989420      0.997092  LogReg  \n",
      "3              0.989127          0.989127      0.997198  LogReg  \n",
      "4              0.989393          0.989393      0.997222  LogReg  \n",
      "5              0.991445          0.991445      0.996227     KNN  \n",
      "6              0.991739          0.991738      0.996477     KNN  \n",
      "7              0.991765          0.991765      0.996677     KNN  \n",
      "8              0.991312          0.991312      0.996081     KNN  \n",
      "9              0.991312          0.991312      0.996379     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.99      0.99     31333\n",
      "      benign       0.99      0.99      0.99     31208\n",
      "\n",
      "    accuracy                           0.99     62541\n",
      "   macro avg       0.99      0.99      0.99     62541\n",
      "weighted avg       0.99      0.99      0.99     62541\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     5.003206    0.098611       0.988674                 0.988681   \n",
      "1     5.322900    0.099633       0.989260                 0.989272   \n",
      "2     4.944912    0.098912       0.989420                 0.989431   \n",
      "3     5.348714    0.116901       0.989127                 0.989134   \n",
      "4     5.561235    0.107373       0.989393                 0.989399   \n",
      "5     0.196815  244.694879       0.991445                 0.991451   \n",
      "6     0.186335  231.440139       0.991739                 0.991745   \n",
      "7     0.228985  248.913006       0.991765                 0.991776   \n",
      "8     0.351334  248.499317       0.991312                 0.991321   \n",
      "9     0.250481  247.239608       0.991312                 0.991317   \n",
      "10  341.521394   80.261028       0.989953                 0.989956   \n",
      "11  284.270764   80.253558       0.989820                 0.989825   \n",
      "12  291.610812   80.451032       0.990513                 0.990518   \n",
      "13  302.904821   95.023440       0.989980                 0.989984   \n",
      "14  300.430932  100.385540       0.990353                 0.990359   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.988674          0.988674      0.997320  LogReg  \n",
      "1               0.989260          0.989260      0.997032  LogReg  \n",
      "2               0.989420          0.989420      0.997092  LogReg  \n",
      "3               0.989127          0.989127      0.997198  LogReg  \n",
      "4               0.989393          0.989393      0.997222  LogReg  \n",
      "5               0.991445          0.991445      0.996227     KNN  \n",
      "6               0.991739          0.991738      0.996477     KNN  \n",
      "7               0.991765          0.991765      0.996677     KNN  \n",
      "8               0.991312          0.991312      0.996081     KNN  \n",
      "9               0.991312          0.991312      0.996379     KNN  \n",
      "10              0.989953          0.989953      0.996925     SVM  \n",
      "11              0.989820          0.989820      0.997122     SVM  \n",
      "12              0.990513          0.990513      0.997471     SVM  \n",
      "13              0.989980          0.989980      0.996684     SVM  \n",
      "14              0.990353          0.990353      0.997385     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.99      0.99     31333\n",
      "      benign       0.99      1.00      0.99     31208\n",
      "\n",
      "    accuracy                           0.99     62541\n",
      "   macro avg       0.99      0.99      0.99     62541\n",
      "weighted avg       0.99      0.99      0.99     62541\n",
      "\n",
      "      fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0     5.003206    0.098611       0.988674                 0.988681   \n",
      "1     5.322900    0.099633       0.989260                 0.989272   \n",
      "2     4.944912    0.098912       0.989420                 0.989431   \n",
      "3     5.348714    0.116901       0.989127                 0.989134   \n",
      "4     5.561235    0.107373       0.989393                 0.989399   \n",
      "5     0.196815  244.694879       0.991445                 0.991451   \n",
      "6     0.186335  231.440139       0.991739                 0.991745   \n",
      "7     0.228985  248.913006       0.991765                 0.991776   \n",
      "8     0.351334  248.499317       0.991312                 0.991321   \n",
      "9     0.250481  247.239608       0.991312                 0.991317   \n",
      "10  341.521394   80.261028       0.989953                 0.989956   \n",
      "11  284.270764   80.253558       0.989820                 0.989825   \n",
      "12  291.610812   80.451032       0.990513                 0.990518   \n",
      "13  302.904821   95.023440       0.989980                 0.989984   \n",
      "14  300.430932  100.385540       0.990353                 0.990359   \n",
      "15    1.409193    0.494186       0.994350                 0.994402   \n",
      "16    0.827122    0.324998       0.993924                 0.993995   \n",
      "17    1.430214    0.334754       0.994244                 0.994307   \n",
      "18    0.829154    0.326394       0.994030                 0.994097   \n",
      "19    1.432832    0.352764       0.993924                 0.993994   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.988674          0.988674      0.997320  LogReg  \n",
      "1               0.989260          0.989260      0.997032  LogReg  \n",
      "2               0.989420          0.989420      0.997092  LogReg  \n",
      "3               0.989127          0.989127      0.997198  LogReg  \n",
      "4               0.989393          0.989393      0.997222  LogReg  \n",
      "5               0.991445          0.991445      0.996227     KNN  \n",
      "6               0.991739          0.991738      0.996477     KNN  \n",
      "7               0.991765          0.991765      0.996677     KNN  \n",
      "8               0.991312          0.991312      0.996081     KNN  \n",
      "9               0.991312          0.991312      0.996379     KNN  \n",
      "10              0.989953          0.989953      0.996925     SVM  \n",
      "11              0.989820          0.989820      0.997122     SVM  \n",
      "12              0.990513          0.990513      0.997471     SVM  \n",
      "13              0.989980          0.989980      0.996684     SVM  \n",
      "14              0.990353          0.990353      0.997385     SVM  \n",
      "15              0.994350          0.994350      0.994601     GNB  \n",
      "16              0.993924          0.993923      0.994036     GNB  \n",
      "17              0.994244          0.994244      0.994383     GNB  \n",
      "18              0.994030          0.994030      0.994180     GNB  \n",
      "19              0.993924          0.993924      0.994109     GNB  \n",
      "4954.820736654001\n"
     ]
    }
   ],
   "source": [
    "#2) Binary\n",
    "df_malicious = pd.concat([df1,df2,df4])\n",
    "df_benign = pd.concat([df12,df13,df15,df17,df22,df23,df27,df28,df29])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Host_s3 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "40a64df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1557230\n",
      "benign: 1556954\n",
      "0 NAN in malicious!\n",
      "55 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1557230\n",
      "benign: 1556899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [04:50<00:00,  1.81s/it]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [04:47<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.96      0.97     38943\n",
      "      benign       0.96      0.98      0.97     38911\n",
      "\n",
      "    accuracy                           0.97     77854\n",
      "   macro avg       0.97      0.97      0.97     77854\n",
      "weighted avg       0.97      0.97      0.97     77854\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  5.882106    0.122118       0.972491                 0.972578   \n",
      "1  5.795565    0.123715       0.973369                 0.973557   \n",
      "2  5.687242    0.122548       0.973690                 0.973775   \n",
      "3  6.081129    0.134138       0.972812                 0.973010   \n",
      "4  6.066511    0.132607       0.971334                 0.971446   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.972491          0.972492      0.990686  LogReg  \n",
      "1              0.973369          0.973366      0.989639  LogReg  \n",
      "2              0.973690          0.973688      0.991148  LogReg  \n",
      "3              0.972812          0.972809      0.989746  LogReg  \n",
      "4              0.971334          0.971332      0.988639  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98     38943\n",
      "      benign       0.98      0.98      0.98     38911\n",
      "\n",
      "    accuracy                           0.98     77854\n",
      "   macro avg       0.98      0.98      0.98     77854\n",
      "weighted avg       0.98      0.98      0.98     77854\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  5.882106    0.122118       0.972491                 0.972578   \n",
      "1  5.795565    0.123715       0.973369                 0.973557   \n",
      "2  5.687242    0.122548       0.973690                 0.973775   \n",
      "3  6.081129    0.134138       0.972812                 0.973010   \n",
      "4  6.066511    0.132607       0.971334                 0.971446   \n",
      "5  0.267809  395.438550       0.977308                 0.977313   \n",
      "6  0.254867  377.125088       0.976837                 0.976848   \n",
      "7  0.248962  394.658049       0.977822                 0.977825   \n",
      "8  0.250523  356.949724       0.977907                 0.977921   \n",
      "9  0.254252  386.767287       0.976665                 0.976673   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.972491          0.972492      0.990686  LogReg  \n",
      "1              0.973369          0.973366      0.989639  LogReg  \n",
      "2              0.973690          0.973688      0.991148  LogReg  \n",
      "3              0.972812          0.972809      0.989746  LogReg  \n",
      "4              0.971334          0.971332      0.988639  LogReg  \n",
      "5              0.977308          0.977308      0.992270     KNN  \n",
      "6              0.976837          0.976837      0.992024     KNN  \n",
      "7              0.977822          0.977821      0.992090     KNN  \n",
      "8              0.977907          0.977907      0.992574     KNN  \n",
      "9              0.976665          0.976665      0.991928     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.97      0.98     38943\n",
      "      benign       0.97      0.99      0.98     38911\n",
      "\n",
      "    accuracy                           0.98     77854\n",
      "   macro avg       0.98      0.98      0.98     77854\n",
      "weighted avg       0.98      0.98      0.98     77854\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      5.882106    0.122118       0.972491                 0.972578   \n",
      "1      5.795565    0.123715       0.973369                 0.973557   \n",
      "2      5.687242    0.122548       0.973690                 0.973775   \n",
      "3      6.081129    0.134138       0.972812                 0.973010   \n",
      "4      6.066511    0.132607       0.971334                 0.971446   \n",
      "5      0.267809  395.438550       0.977308                 0.977313   \n",
      "6      0.254867  377.125088       0.976837                 0.976848   \n",
      "7      0.248962  394.658049       0.977822                 0.977825   \n",
      "8      0.250523  356.949724       0.977907                 0.977921   \n",
      "9      0.254252  386.767287       0.976665                 0.976673   \n",
      "10  2174.111626  459.548727       0.978400                 0.978633   \n",
      "11  2089.164876  359.932829       0.978271                 0.978558   \n",
      "12  1129.264594  396.987565       0.979470                 0.979653   \n",
      "13  1131.642851  391.214281       0.979320                 0.979576   \n",
      "14  1637.587776  387.329288       0.976879                 0.977123   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.972491          0.972492      0.990686  LogReg  \n",
      "1               0.973369          0.973366      0.989639  LogReg  \n",
      "2               0.973690          0.973688      0.991148  LogReg  \n",
      "3               0.972812          0.972809      0.989746  LogReg  \n",
      "4               0.971334          0.971332      0.988639  LogReg  \n",
      "5               0.977308          0.977308      0.992270     KNN  \n",
      "6               0.976837          0.976837      0.992024     KNN  \n",
      "7               0.977822          0.977821      0.992090     KNN  \n",
      "8               0.977907          0.977907      0.992574     KNN  \n",
      "9               0.976665          0.976665      0.991928     KNN  \n",
      "10              0.978400          0.978399      0.994128     SVM  \n",
      "11              0.978271          0.978267      0.993597     SVM  \n",
      "12              0.979470          0.979467      0.993870     SVM  \n",
      "13              0.979320          0.979317      0.993908     SVM  \n",
      "14              0.976879          0.976875      0.992494     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.95      0.96     38943\n",
      "      benign       0.95      0.97      0.96     38911\n",
      "\n",
      "    accuracy                           0.96     77854\n",
      "   macro avg       0.96      0.96      0.96     77854\n",
      "weighted avg       0.96      0.96      0.96     77854\n",
      "\n",
      "       fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0      5.882106    0.122118       0.972491                 0.972578   \n",
      "1      5.795565    0.123715       0.973369                 0.973557   \n",
      "2      5.687242    0.122548       0.973690                 0.973775   \n",
      "3      6.081129    0.134138       0.972812                 0.973010   \n",
      "4      6.066511    0.132607       0.971334                 0.971446   \n",
      "5      0.267809  395.438550       0.977308                 0.977313   \n",
      "6      0.254867  377.125088       0.976837                 0.976848   \n",
      "7      0.248962  394.658049       0.977822                 0.977825   \n",
      "8      0.250523  356.949724       0.977907                 0.977921   \n",
      "9      0.254252  386.767287       0.976665                 0.976673   \n",
      "10  2174.111626  459.548727       0.978400                 0.978633   \n",
      "11  2089.164876  359.932829       0.978271                 0.978558   \n",
      "12  1129.264594  396.987565       0.979470                 0.979653   \n",
      "13  1131.642851  391.214281       0.979320                 0.979576   \n",
      "14  1637.587776  387.329288       0.976879                 0.977123   \n",
      "15     1.072502    0.481891       0.962515                 0.962826   \n",
      "16     1.068070    0.487476       0.961659                 0.961924   \n",
      "17     1.059199    0.481936       0.965319                 0.965553   \n",
      "18     1.062571    0.482929       0.965662                 0.966070   \n",
      "19     1.067927    0.484000       0.961380                 0.961615   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.972491          0.972492      0.990686  LogReg  \n",
      "1               0.973369          0.973366      0.989639  LogReg  \n",
      "2               0.973690          0.973688      0.991148  LogReg  \n",
      "3               0.972812          0.972809      0.989746  LogReg  \n",
      "4               0.971334          0.971332      0.988639  LogReg  \n",
      "5               0.977308          0.977308      0.992270     KNN  \n",
      "6               0.976837          0.976837      0.992024     KNN  \n",
      "7               0.977822          0.977821      0.992090     KNN  \n",
      "8               0.977907          0.977907      0.992574     KNN  \n",
      "9               0.976665          0.976665      0.991928     KNN  \n",
      "10              0.978400          0.978399      0.994128     SVM  \n",
      "11              0.978271          0.978267      0.993597     SVM  \n",
      "12              0.979470          0.979467      0.993870     SVM  \n",
      "13              0.979320          0.979317      0.993908     SVM  \n",
      "14              0.976879          0.976875      0.992494     SVM  \n",
      "15              0.962515          0.962513      0.974440     GNB  \n",
      "16              0.961659          0.961653      0.974041     GNB  \n",
      "17              0.965319          0.965313      0.976381     GNB  \n",
      "18              0.965662          0.965654      0.974943     GNB  \n",
      "19              0.961380          0.961373      0.974102     GNB  \n",
      "19153.22254407\n"
     ]
    }
   ],
   "source": [
    "## S4: Fully compromised (All)\n",
    " \n",
    "df_malicious = pd.concat([df1,df2,df3,df4,df5,df6,df7,df32,df33,df34,df35])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df11,df10,df12,df13,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df30,df27,df29])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "58b99722",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 247143\n",
      "benign: 246001\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 247143\n",
      "benign: 246001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:37<00:00,  4.24it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:38<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.98      0.98      6074\n",
      "      benign       0.98      0.97      0.98      6255\n",
      "\n",
      "    accuracy                           0.98     12329\n",
      "   macro avg       0.98      0.98      0.98     12329\n",
      "weighted avg       0.98      0.98      0.98     12329\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.083015    0.025859       0.973506                 0.973511   \n",
      "1  0.946127    0.023898       0.979995                 0.979995   \n",
      "2  1.000458    0.022815       0.976612                 0.976629   \n",
      "3  1.068167    0.022077       0.977694                 0.977694   \n",
      "4  0.943920    0.024133       0.978099                 0.978101   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.973506          0.973506      0.996737  LogReg  \n",
      "1              0.979995          0.979995      0.997823  LogReg  \n",
      "2              0.976612          0.976613      0.997288  LogReg  \n",
      "3              0.977694          0.977694      0.997514  LogReg  \n",
      "4              0.978099          0.978099      0.997517  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.97      0.97      6074\n",
      "      benign       0.97      0.97      0.97      6255\n",
      "\n",
      "    accuracy                           0.97     12329\n",
      "   macro avg       0.97      0.97      0.97     12329\n",
      "weighted avg       0.97      0.97      0.97     12329\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.083015    0.025859       0.973506                 0.973511   \n",
      "1  0.946127    0.023898       0.979995                 0.979995   \n",
      "2  1.000458    0.022815       0.976612                 0.976629   \n",
      "3  1.068167    0.022077       0.977694                 0.977694   \n",
      "4  0.943920    0.024133       0.978099                 0.978101   \n",
      "5  0.043693    9.521030       0.967288                 0.967297   \n",
      "6  0.044969    9.578156       0.969181                 0.969181   \n",
      "7  0.034971    9.559942       0.970393                 0.970396   \n",
      "8  0.047522    9.329350       0.972286                 0.972288   \n",
      "9  0.036972    9.746725       0.969312                 0.969313   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.973506          0.973506      0.996737  LogReg  \n",
      "1              0.979995          0.979995      0.997823  LogReg  \n",
      "2              0.976612          0.976613      0.997288  LogReg  \n",
      "3              0.977694          0.977694      0.997514  LogReg  \n",
      "4              0.978099          0.978099      0.997517  LogReg  \n",
      "5              0.967288          0.967288      0.990634     KNN  \n",
      "6              0.969181          0.969181      0.990803     KNN  \n",
      "7              0.970393          0.970394      0.992727     KNN  \n",
      "8              0.972286          0.972286      0.992656     KNN  \n",
      "9              0.969312          0.969311      0.991639     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98      6074\n",
      "      benign       0.99      0.98      0.98      6255\n",
      "\n",
      "    accuracy                           0.98     12329\n",
      "   macro avg       0.98      0.98      0.98     12329\n",
      "weighted avg       0.98      0.98      0.98     12329\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.083015    0.025859       0.973506                 0.973511   \n",
      "1    0.946127    0.023898       0.979995                 0.979995   \n",
      "2    1.000458    0.022815       0.976612                 0.976629   \n",
      "3    1.068167    0.022077       0.977694                 0.977694   \n",
      "4    0.943920    0.024133       0.978099                 0.978101   \n",
      "5    0.043693    9.521030       0.967288                 0.967297   \n",
      "6    0.044969    9.578156       0.969181                 0.969181   \n",
      "7    0.034971    9.559942       0.970393                 0.970396   \n",
      "8    0.047522    9.329350       0.972286                 0.972288   \n",
      "9    0.036972    9.746725       0.969312                 0.969313   \n",
      "10  22.245659   10.879345       0.977697                 0.977701   \n",
      "11  22.270937   10.921839       0.980806                 0.980806   \n",
      "12  21.959669   10.907224       0.981209                 0.981229   \n",
      "13  22.300447   10.912856       0.981885                 0.981890   \n",
      "14  22.395262   10.926249       0.981344                 0.981344   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.973506          0.973506      0.996737  LogReg  \n",
      "1               0.979995          0.979995      0.997823  LogReg  \n",
      "2               0.976612          0.976613      0.997288  LogReg  \n",
      "3               0.977694          0.977694      0.997514  LogReg  \n",
      "4               0.978099          0.978099      0.997517  LogReg  \n",
      "5               0.967288          0.967288      0.990634     KNN  \n",
      "6               0.969181          0.969181      0.990803     KNN  \n",
      "7               0.970393          0.970394      0.992727     KNN  \n",
      "8               0.972286          0.972286      0.992656     KNN  \n",
      "9               0.969312          0.969311      0.991639     KNN  \n",
      "10              0.977697          0.977697      0.996433     SVM  \n",
      "11              0.980806          0.980806      0.997480     SVM  \n",
      "12              0.981209          0.981209      0.997349     SVM  \n",
      "13              0.981885          0.981885      0.997415     SVM  \n",
      "14              0.981344          0.981344      0.997225     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00      6074\n",
      "      benign       1.00      1.00      1.00      6255\n",
      "\n",
      "    accuracy                           1.00     12329\n",
      "   macro avg       1.00      1.00      1.00     12329\n",
      "weighted avg       1.00      1.00      1.00     12329\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.083015    0.025859       0.973506                 0.973511   \n",
      "1    0.946127    0.023898       0.979995                 0.979995   \n",
      "2    1.000458    0.022815       0.976612                 0.976629   \n",
      "3    1.068167    0.022077       0.977694                 0.977694   \n",
      "4    0.943920    0.024133       0.978099                 0.978101   \n",
      "5    0.043693    9.521030       0.967288                 0.967297   \n",
      "6    0.044969    9.578156       0.969181                 0.969181   \n",
      "7    0.034971    9.559942       0.970393                 0.970396   \n",
      "8    0.047522    9.329350       0.972286                 0.972288   \n",
      "9    0.036972    9.746725       0.969312                 0.969313   \n",
      "10  22.245659   10.879345       0.977697                 0.977701   \n",
      "11  22.270937   10.921839       0.980806                 0.980806   \n",
      "12  21.959669   10.907224       0.981209                 0.981229   \n",
      "13  22.300447   10.912856       0.981885                 0.981890   \n",
      "14  22.395262   10.926249       0.981344                 0.981344   \n",
      "15   0.141468    0.050237       0.999594                 0.999595   \n",
      "16   0.127383    0.044898       0.999865                 0.999865   \n",
      "17   0.126644    0.048108       0.999594                 0.999595   \n",
      "18   0.126853    0.044586       0.999594                 0.999595   \n",
      "19   0.126793    0.043990       0.999865                 0.999865   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.973506          0.973506      0.996737  LogReg  \n",
      "1               0.979995          0.979995      0.997823  LogReg  \n",
      "2               0.976612          0.976613      0.997288  LogReg  \n",
      "3               0.977694          0.977694      0.997514  LogReg  \n",
      "4               0.978099          0.978099      0.997517  LogReg  \n",
      "5               0.967288          0.967288      0.990634     KNN  \n",
      "6               0.969181          0.969181      0.990803     KNN  \n",
      "7               0.970393          0.970394      0.992727     KNN  \n",
      "8               0.972286          0.972286      0.992656     KNN  \n",
      "9               0.969312          0.969311      0.991639     KNN  \n",
      "10              0.977697          0.977697      0.996433     SVM  \n",
      "11              0.980806          0.980806      0.997480     SVM  \n",
      "12              0.981209          0.981209      0.997349     SVM  \n",
      "13              0.981885          0.981885      0.997415     SVM  \n",
      "14              0.981344          0.981344      0.997225     SVM  \n",
      "15              0.999594          0.999594      0.999594     GNB  \n",
      "16              0.999865          0.999865      0.999866     GNB  \n",
      "17              0.999594          0.999594      0.999600     GNB  \n",
      "18              0.999594          0.999594      0.999599     GNB  \n",
      "19              0.999865          0.999865      0.999862     GNB  \n",
      "435.41981793698505\n"
     ]
    }
   ],
   "source": [
    "## S5: Partially compromised (IoT + Laptop)\n",
    " \n",
    "df_malicious = pd.concat([df5,df35])\n",
    " \n",
    "df_benign = pd.concat([df14,df16,df18,df19,df20])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e3f04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 12871\n",
      "benign: 13746\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 12871\n",
      "benign: 13746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 144/144 [00:02<00:00, 48.00it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 153/153 [00:03<00:00, 50.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "SVM-linear-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.93      0.95       363\n",
      "      benign       0.92      0.96      0.94       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  46.181343    0.011134       0.942500                 0.942484   \n",
      "1   6.304723    0.009347       0.942500                 0.942634   \n",
      "2  43.386375    0.010828       0.939850                 0.939862   \n",
      "3  25.759007    0.009978       0.944862                 0.944923   \n",
      "4  13.542591    0.008832       0.922306                 0.922311   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1              0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2              0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3              0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4              0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "SVM-poly-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.96      0.97       363\n",
      "      benign       0.95      0.98      0.96       303\n",
      "\n",
      "    accuracy                           0.97       666\n",
      "   macro avg       0.96      0.97      0.97       666\n",
      "weighted avg       0.97      0.97      0.97       666\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  46.181343    0.011134       0.942500                 0.942484   \n",
      "1   6.304723    0.009347       0.942500                 0.942634   \n",
      "2  43.386375    0.010828       0.939850                 0.939862   \n",
      "3  25.759007    0.009978       0.944862                 0.944923   \n",
      "4  13.542591    0.008832       0.922306                 0.922311   \n",
      "5   0.088870    0.022612       0.922500                 0.923278   \n",
      "6   0.088983    0.023686       0.930000                 0.930228   \n",
      "7   0.091771    0.022799       0.942356                 0.942411   \n",
      "8   0.090027    0.022798       0.949875                 0.949948   \n",
      "9   0.086144    0.021468       0.919799                 0.920150   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1              0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2              0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3              0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4              0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "5              0.922500          0.922606      0.981458    SVM-poly-scale-1  \n",
      "6              0.930000          0.930021      0.967698    SVM-poly-scale-1  \n",
      "7              0.942356          0.942330      0.986117    SVM-poly-scale-1  \n",
      "8              0.949875          0.949815      0.983807    SVM-poly-scale-1  \n",
      "9              0.919799          0.919766      0.959893    SVM-poly-scale-1  \n",
      "SVM-rbf-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.95      0.93      0.94       363\n",
      "      benign       0.92      0.94      0.93       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458    SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698    SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117    SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807    SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893    SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378     SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772     SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212     SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816     SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868     SVM-rbf-scale-1  \n",
      "SVM-sigmoid-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.72      0.63      0.67       363\n",
      "      benign       0.61      0.71      0.66       303\n",
      "\n",
      "    accuracy                           0.66       666\n",
      "   macro avg       0.67      0.67      0.66       666\n",
      "weighted avg       0.67      0.66      0.66       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.93      0.95       363\n",
      "      benign       0.92      0.96      0.94       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "SVM-poly-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.94      0.96       363\n",
      "      benign       0.93      0.97      0.95       303\n",
      "\n",
      "    accuracy                           0.95       666\n",
      "   macro avg       0.95      0.95      0.95       666\n",
      "weighted avg       0.95      0.95      0.95       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.61      1.00      0.76       363\n",
      "      benign       1.00      0.24      0.39       303\n",
      "\n",
      "    accuracy                           0.66       666\n",
      "   macro avg       0.81      0.62      0.58       666\n",
      "weighted avg       0.79      0.66      0.59       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "SVM-sigmoid-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.55      1.00      0.71       363\n",
      "      benign       0.00      0.00      0.00       303\n",
      "\n",
      "    accuracy                           0.55       666\n",
      "   macro avg       0.27      0.50      0.35       666\n",
      "weighted avg       0.30      0.55      0.38       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.93      0.95       363\n",
      "      benign       0.92      0.96      0.94       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "40  46.010785    0.010554       0.942500                 0.942484   \n",
      "41   6.266292    0.008838       0.942500                 0.942634   \n",
      "42  43.147571    0.010631       0.939850                 0.939862   \n",
      "43  25.692864    0.009347       0.944862                 0.944923   \n",
      "44  13.510476    0.009579       0.922306                 0.922311   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.942500          0.942486      0.984359   SVM-linear-scale-2  \n",
      "41              0.942500          0.942514      0.979167   SVM-linear-scale-2  \n",
      "42              0.939850          0.939832      0.977198   SVM-linear-scale-2  \n",
      "43              0.944862          0.944796      0.970842   SVM-linear-scale-2  \n",
      "44              0.922306          0.922303      0.968136   SVM-linear-scale-2  \n",
      "SVM-poly-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      0.96      0.97       363\n",
      "      benign       0.96      0.98      0.97       303\n",
      "\n",
      "    accuracy                           0.97       666\n",
      "   macro avg       0.97      0.97      0.97       666\n",
      "weighted avg       0.97      0.97      0.97       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "40  46.010785    0.010554       0.942500                 0.942484   \n",
      "41   6.266292    0.008838       0.942500                 0.942634   \n",
      "42  43.147571    0.010631       0.939850                 0.939862   \n",
      "43  25.692864    0.009347       0.944862                 0.944923   \n",
      "44  13.510476    0.009579       0.922306                 0.922311   \n",
      "45   0.089366    0.020880       0.932500                 0.933257   \n",
      "46   0.087524    0.021850       0.942500                 0.942500   \n",
      "47   0.092854    0.021654       0.954887                 0.955023   \n",
      "48   0.087491    0.021064       0.952381                 0.952539   \n",
      "49   0.082500    0.020168       0.927318                 0.927324   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.942500          0.942486      0.984359   SVM-linear-scale-2  \n",
      "41              0.942500          0.942514      0.979167   SVM-linear-scale-2  \n",
      "42              0.939850          0.939832      0.977198   SVM-linear-scale-2  \n",
      "43              0.944862          0.944796      0.970842   SVM-linear-scale-2  \n",
      "44              0.922306          0.922303      0.968136   SVM-linear-scale-2  \n",
      "45              0.932500          0.932592      0.983198     SVM-poly-scale-2  \n",
      "46              0.942500          0.942494      0.968850     SVM-poly-scale-2  \n",
      "47              0.954887          0.954859      0.988561     SVM-poly-scale-2  \n",
      "48              0.952381          0.952308      0.985663     SVM-poly-scale-2  \n",
      "49              0.927318          0.927316      0.969644     SVM-poly-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-rbf-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.95      0.96       363\n",
      "      benign       0.94      0.97      0.96       303\n",
      "\n",
      "    accuracy                           0.96       666\n",
      "   macro avg       0.96      0.96      0.96       666\n",
      "weighted avg       0.96      0.96      0.96       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "40  46.010785    0.010554       0.942500                 0.942484   \n",
      "41   6.266292    0.008838       0.942500                 0.942634   \n",
      "42  43.147571    0.010631       0.939850                 0.939862   \n",
      "43  25.692864    0.009347       0.944862                 0.944923   \n",
      "44  13.510476    0.009579       0.922306                 0.922311   \n",
      "45   0.089366    0.020880       0.932500                 0.933257   \n",
      "46   0.087524    0.021850       0.942500                 0.942500   \n",
      "47   0.092854    0.021654       0.954887                 0.955023   \n",
      "48   0.087491    0.021064       0.952381                 0.952539   \n",
      "49   0.082500    0.020168       0.927318                 0.927324   \n",
      "50   0.089105    0.074795       0.917500                 0.917476   \n",
      "51   0.091143    0.074924       0.917500                 0.917644   \n",
      "52   0.092662    0.084401       0.949875                 0.950205   \n",
      "53   0.091640    0.084092       0.947368                 0.947351   \n",
      "54   0.088725    0.083277       0.909774                 0.909917   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.942500          0.942486      0.984359   SVM-linear-scale-2  \n",
      "41              0.942500          0.942514      0.979167   SVM-linear-scale-2  \n",
      "42              0.939850          0.939832      0.977198   SVM-linear-scale-2  \n",
      "43              0.944862          0.944796      0.970842   SVM-linear-scale-2  \n",
      "44              0.922306          0.922303      0.968136   SVM-linear-scale-2  \n",
      "45              0.932500          0.932592      0.983198     SVM-poly-scale-2  \n",
      "46              0.942500          0.942494      0.968850     SVM-poly-scale-2  \n",
      "47              0.954887          0.954859      0.988561     SVM-poly-scale-2  \n",
      "48              0.952381          0.952308      0.985663     SVM-poly-scale-2  \n",
      "49              0.927318          0.927316      0.969644     SVM-poly-scale-2  \n",
      "50              0.917500          0.917436      0.982265      SVM-rbf-scale-2  \n",
      "51              0.917500          0.917520      0.970853      SVM-rbf-scale-2  \n",
      "52              0.949875          0.949823      0.988108      SVM-rbf-scale-2  \n",
      "53              0.947368          0.947354      0.985383      SVM-rbf-scale-2  \n",
      "54              0.909774          0.909754      0.964844      SVM-rbf-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-sigmoid-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.71      0.62      0.66       363\n",
      "      benign       0.60      0.70      0.65       303\n",
      "\n",
      "    accuracy                           0.65       666\n",
      "   macro avg       0.66      0.66      0.65       666\n",
      "weighted avg       0.66      0.65      0.66       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "5    0.088870    0.022612       0.922500                 0.923278   \n",
      "6    0.088983    0.023686       0.930000                 0.930228   \n",
      "7    0.091771    0.022799       0.942356                 0.942411   \n",
      "8    0.090027    0.022798       0.949875                 0.949948   \n",
      "9    0.086144    0.021468       0.919799                 0.920150   \n",
      "10   0.095671    0.089227       0.917500                 0.917471   \n",
      "11   0.096820    0.084331       0.915000                 0.915000   \n",
      "12   0.101153    0.087032       0.924812                 0.924815   \n",
      "13   0.098781    0.087209       0.937343                 0.937546   \n",
      "14   0.093754    0.082441       0.899749                 0.899749   \n",
      "15   0.123241    0.054576       0.655000                 0.661889   \n",
      "16   0.125698    0.055018       0.682500                 0.682932   \n",
      "17   0.124899    0.054710       0.704261                 0.704029   \n",
      "18   0.120419    0.052448       0.649123                 0.660864   \n",
      "19   0.132873    0.056724       0.719298                 0.720137   \n",
      "20  45.977869    0.010632       0.942500                 0.942484   \n",
      "21   6.266010    0.008849       0.942500                 0.942634   \n",
      "22  43.089100    0.010611       0.939850                 0.939862   \n",
      "23  25.747722    0.009287       0.944862                 0.944923   \n",
      "24  13.513739    0.009616       0.922306                 0.922311   \n",
      "25   0.083364    0.014358       0.912500                 0.912968   \n",
      "26   0.077085    0.014958       0.930000                 0.930116   \n",
      "27   0.086191    0.014195       0.947368                 0.947394   \n",
      "28   0.090906    0.014297       0.934837                 0.934837   \n",
      "29   0.084215    0.013920       0.929825                 0.930015   \n",
      "30   0.261639    0.242236       0.655000                 0.788361   \n",
      "31   0.260749    0.243577       0.670000                 0.798118   \n",
      "32   0.261511    0.260776       0.661654                 0.794050   \n",
      "33   0.260633    0.227832       0.601504                 0.789518   \n",
      "34   0.256737    0.258841       0.619048                 0.784964   \n",
      "35   0.223821    0.091820       0.452500                 0.204756   \n",
      "36   0.224150    0.091597       0.520000                 0.270400   \n",
      "37   0.224631    0.090979       0.526316                 0.277008   \n",
      "38   0.215457    0.087864       0.446115                 0.199019   \n",
      "39   0.220230    0.089959       0.493734                 0.243774   \n",
      "40  46.010785    0.010554       0.942500                 0.942484   \n",
      "41   6.266292    0.008838       0.942500                 0.942634   \n",
      "42  43.147571    0.010631       0.939850                 0.939862   \n",
      "43  25.692864    0.009347       0.944862                 0.944923   \n",
      "44  13.510476    0.009579       0.922306                 0.922311   \n",
      "45   0.089366    0.020880       0.932500                 0.933257   \n",
      "46   0.087524    0.021850       0.942500                 0.942500   \n",
      "47   0.092854    0.021654       0.954887                 0.955023   \n",
      "48   0.087491    0.021064       0.952381                 0.952539   \n",
      "49   0.082500    0.020168       0.927318                 0.927324   \n",
      "50   0.089105    0.074795       0.917500                 0.917476   \n",
      "51   0.091143    0.074924       0.917500                 0.917644   \n",
      "52   0.092662    0.084401       0.949875                 0.950205   \n",
      "53   0.091640    0.084092       0.947368                 0.947351   \n",
      "54   0.088725    0.083277       0.909774                 0.909917   \n",
      "55   0.116246    0.051308       0.652500                 0.659748   \n",
      "56   0.120689    0.052659       0.672500                 0.672935   \n",
      "57   0.121225    0.052711       0.696742                 0.696827   \n",
      "58   0.114120    0.050644       0.636591                 0.647717   \n",
      "59   0.128382    0.055509       0.699248                 0.699561   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.942500          0.942486      0.984359   SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167   SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198   SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842   SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136   SVM-linear-scale-1  \n",
      "5               0.922500          0.922606      0.981458     SVM-poly-scale-1  \n",
      "6               0.930000          0.930021      0.967698     SVM-poly-scale-1  \n",
      "7               0.942356          0.942330      0.986117     SVM-poly-scale-1  \n",
      "8               0.949875          0.949815      0.983807     SVM-poly-scale-1  \n",
      "9               0.919799          0.919766      0.959893     SVM-poly-scale-1  \n",
      "10              0.917500          0.917480      0.975378      SVM-rbf-scale-1  \n",
      "11              0.915000          0.915000      0.966772      SVM-rbf-scale-1  \n",
      "12              0.924812          0.924790      0.982212      SVM-rbf-scale-1  \n",
      "13              0.937343          0.937391      0.982816      SVM-rbf-scale-1  \n",
      "14              0.899749          0.899749      0.959868      SVM-rbf-scale-1  \n",
      "15              0.655000          0.655673      0.739322  SVM-sigmoid-scale-1  \n",
      "16              0.682500          0.682609      0.781976  SVM-sigmoid-scale-1  \n",
      "17              0.704261          0.704074      0.783321  SVM-sigmoid-scale-1  \n",
      "18              0.649123          0.649678      0.772688  SVM-sigmoid-scale-1  \n",
      "19              0.719298          0.718828      0.773936  SVM-sigmoid-scale-1  \n",
      "20              0.942500          0.942486      0.984359    SVM-linear-auto-1  \n",
      "21              0.942500          0.942514      0.979167    SVM-linear-auto-1  \n",
      "22              0.939850          0.939832      0.977198    SVM-linear-auto-1  \n",
      "23              0.944862          0.944796      0.970842    SVM-linear-auto-1  \n",
      "24              0.922306          0.922303      0.968136    SVM-linear-auto-1  \n",
      "25              0.912500          0.912591      0.973259      SVM-poly-auto-1  \n",
      "26              0.930000          0.929965      0.970252      SVM-poly-auto-1  \n",
      "27              0.947368          0.947375      0.985034      SVM-poly-auto-1  \n",
      "28              0.934837          0.934837      0.979460      SVM-poly-auto-1  \n",
      "29              0.929825          0.929826      0.959014      SVM-poly-auto-1  \n",
      "30              0.655000          0.590056      0.643154       SVM-rbf-auto-1  \n",
      "31              0.670000          0.623316      0.673615       SVM-rbf-auto-1  \n",
      "32              0.661654          0.608819      0.661565       SVM-rbf-auto-1  \n",
      "33              0.601504          0.551074      0.650376       SVM-rbf-auto-1  \n",
      "34              0.619048          0.557184      0.639041       SVM-rbf-auto-1  \n",
      "35              0.452500          0.281936      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.520000          0.355789      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.526316          0.362976      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.446115          0.275246      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.493734          0.326395      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.942500          0.942486      0.984359   SVM-linear-scale-2  \n",
      "41              0.942500          0.942514      0.979167   SVM-linear-scale-2  \n",
      "42              0.939850          0.939832      0.977198   SVM-linear-scale-2  \n",
      "43              0.944862          0.944796      0.970842   SVM-linear-scale-2  \n",
      "44              0.922306          0.922303      0.968136   SVM-linear-scale-2  \n",
      "45              0.932500          0.932592      0.983198     SVM-poly-scale-2  \n",
      "46              0.942500          0.942494      0.968850     SVM-poly-scale-2  \n",
      "47              0.954887          0.954859      0.988561     SVM-poly-scale-2  \n",
      "48              0.952381          0.952308      0.985663     SVM-poly-scale-2  \n",
      "49              0.927318          0.927316      0.969644     SVM-poly-scale-2  \n",
      "50              0.917500          0.917436      0.982265      SVM-rbf-scale-2  \n",
      "51              0.917500          0.917520      0.970853      SVM-rbf-scale-2  \n",
      "52              0.949875          0.949823      0.988108      SVM-rbf-scale-2  \n",
      "53              0.947368          0.947354      0.985383      SVM-rbf-scale-2  \n",
      "54              0.909774          0.909754      0.964844      SVM-rbf-scale-2  \n",
      "55              0.652500          0.653146      0.728298  SVM-sigmoid-scale-2  \n",
      "56              0.672500          0.672613      0.775716  SVM-sigmoid-scale-2  \n",
      "57              0.696742          0.696780      0.777072  SVM-sigmoid-scale-2  \n",
      "58              0.636591          0.637231      0.766841  SVM-sigmoid-scale-2  \n",
      "59              0.699248          0.698964      0.763985  SVM-sigmoid-scale-2  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-linear-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.93      0.95       363\n",
      "      benign       0.92      0.96      0.94       303\n",
      "\n",
      "    accuracy                           0.94       666\n",
      "   macro avg       0.94      0.94      0.94       666\n",
      "weighted avg       0.94      0.94      0.94       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "..        ...         ...            ...                      ...   \n",
      "60  45.901424    0.010624       0.942500                 0.942484   \n",
      "61   6.307388    0.009160       0.942500                 0.942634   \n",
      "62  43.155742    0.010664       0.939850                 0.939862   \n",
      "63  25.684432    0.010112       0.944862                 0.944923   \n",
      "64  13.522271    0.009664       0.922306                 0.922311   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "60              0.942500          0.942486      0.984359   SVM-linear-auto-2  \n",
      "61              0.942500          0.942514      0.979167   SVM-linear-auto-2  \n",
      "62              0.939850          0.939832      0.977198   SVM-linear-auto-2  \n",
      "63              0.944862          0.944796      0.970842   SVM-linear-auto-2  \n",
      "64              0.922306          0.922303      0.968136   SVM-linear-auto-2  \n",
      "\n",
      "[65 rows x 8 columns]\n",
      "SVM-poly-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.94      0.96       363\n",
      "      benign       0.93      0.97      0.95       303\n",
      "\n",
      "    accuracy                           0.95       666\n",
      "   macro avg       0.95      0.95      0.95       666\n",
      "weighted avg       0.95      0.95      0.95       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "..        ...         ...            ...                      ...   \n",
      "65   0.083372    0.014378       0.912500                 0.912968   \n",
      "66   0.077464    0.014755       0.930000                 0.930116   \n",
      "67   0.085998    0.014179       0.947368                 0.947394   \n",
      "68   0.091285    0.014478       0.934837                 0.934837   \n",
      "69   0.085450    0.014077       0.929825                 0.930015   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "65              0.912500          0.912591      0.973259     SVM-poly-auto-2  \n",
      "66              0.930000          0.929965      0.970252     SVM-poly-auto-2  \n",
      "67              0.947368          0.947375      0.985034     SVM-poly-auto-2  \n",
      "68              0.934837          0.934837      0.979460     SVM-poly-auto-2  \n",
      "69              0.929825          0.929826      0.959014     SVM-poly-auto-2  \n",
      "\n",
      "[70 rows x 8 columns]\n",
      "SVM-rbf-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.61      1.00      0.76       363\n",
      "      benign       1.00      0.24      0.39       303\n",
      "\n",
      "    accuracy                           0.66       666\n",
      "   macro avg       0.81      0.62      0.58       666\n",
      "weighted avg       0.79      0.66      0.59       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "..        ...         ...            ...                      ...   \n",
      "70   0.259884    0.227668       0.655000                 0.788361   \n",
      "71   0.260453    0.257884       0.670000                 0.798118   \n",
      "72   0.253305    0.237293       0.661654                 0.794050   \n",
      "73   0.257602    0.245082       0.601504                 0.789518   \n",
      "74   0.252234    0.233901       0.619048                 0.784964   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "70              0.655000          0.590056      0.643154      SVM-rbf-auto-2  \n",
      "71              0.670000          0.623316      0.673615      SVM-rbf-auto-2  \n",
      "72              0.661654          0.608819      0.661565      SVM-rbf-auto-2  \n",
      "73              0.601504          0.551074      0.650376      SVM-rbf-auto-2  \n",
      "74              0.619048          0.557184      0.639041      SVM-rbf-auto-2  \n",
      "\n",
      "[75 rows x 8 columns]\n",
      "SVM-sigmoid-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.55      1.00      0.71       363\n",
      "      benign       0.00      0.00      0.00       303\n",
      "\n",
      "    accuracy                           0.55       666\n",
      "   macro avg       0.27      0.50      0.35       666\n",
      "weighted avg       0.30      0.55      0.38       666\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   46.181343    0.011134       0.942500                 0.942484   \n",
      "1    6.304723    0.009347       0.942500                 0.942634   \n",
      "2   43.386375    0.010828       0.939850                 0.939862   \n",
      "3   25.759007    0.009978       0.944862                 0.944923   \n",
      "4   13.542591    0.008832       0.922306                 0.922311   \n",
      "..        ...         ...            ...                      ...   \n",
      "75   0.227059    0.091461       0.452500                 0.204756   \n",
      "76   0.225473    0.091357       0.520000                 0.270400   \n",
      "77   0.224463    0.091375       0.526316                 0.277008   \n",
      "78   0.215802    0.088098       0.446115                 0.199019   \n",
      "79   0.220964    0.089993       0.493734                 0.243774   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.942500          0.942486      0.984359  SVM-linear-scale-1  \n",
      "1               0.942500          0.942514      0.979167  SVM-linear-scale-1  \n",
      "2               0.939850          0.939832      0.977198  SVM-linear-scale-1  \n",
      "3               0.944862          0.944796      0.970842  SVM-linear-scale-1  \n",
      "4               0.922306          0.922303      0.968136  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "75              0.452500          0.281936      0.500000  SVM-sigmoid-auto-2  \n",
      "76              0.520000          0.355789      0.500000  SVM-sigmoid-auto-2  \n",
      "77              0.526316          0.362976      0.500000  SVM-sigmoid-auto-2  \n",
      "78              0.446115          0.275246      0.500000  SVM-sigmoid-auto-2  \n",
      "79              0.493734          0.326395      0.500000  SVM-sigmoid-auto-2  \n",
      "\n",
      "[80 rows x 8 columns]\n",
      "1205.643477513\n"
     ]
    }
   ],
   "source": [
    "## S6: Single compromised (IoT) (Raspberry)\n",
    " \n",
    "df_malicious = pd.concat([df5])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10])\n",
    "\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f7741fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 47978\n",
      "benign: 47801\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 47978\n",
      "benign: 47801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:09<00:00, 16.86it/s]\n",
      "Feature Extraction: 100%|█████████████████████| 160/160 [00:09<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.92      0.92      0.92      1206\n",
      "      benign       0.92      0.92      0.92      1189\n",
      "\n",
      "    accuracy                           0.92      2395\n",
      "   macro avg       0.92      0.92      0.92      2395\n",
      "weighted avg       0.92      0.92      0.92      2395\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.239554    0.021149       0.915101                 0.915147   \n",
      "1  0.202220    0.009345       0.913709                 0.913709   \n",
      "2  0.188308    0.009803       0.905358                 0.905534   \n",
      "3  0.329162    0.009122       0.928323                 0.928429   \n",
      "4  0.259995    0.009196       0.919916                 0.919914   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.915101          0.915108      0.976453  LogReg  \n",
      "1              0.913709          0.913709      0.974774  LogReg  \n",
      "2              0.905358          0.905360      0.966887  LogReg  \n",
      "3              0.928323          0.928321      0.973413  LogReg  \n",
      "4              0.919916          0.919911      0.977326  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.91      0.92      0.91      1206\n",
      "      benign       0.91      0.91      0.91      1189\n",
      "\n",
      "    accuracy                           0.91      2395\n",
      "   macro avg       0.91      0.91      0.91      2395\n",
      "weighted avg       0.91      0.91      0.91      2395\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.239554    0.021149       0.915101                 0.915147   \n",
      "1  0.202220    0.009345       0.913709                 0.913709   \n",
      "2  0.188308    0.009803       0.905358                 0.905534   \n",
      "3  0.329162    0.009122       0.928323                 0.928429   \n",
      "4  0.259995    0.009196       0.919916                 0.919914   \n",
      "5  0.091616    0.502946       0.901183                 0.901193   \n",
      "6  0.005744    0.377867       0.901879                 0.902076   \n",
      "7  0.005781    0.356251       0.897008                 0.897227   \n",
      "8  0.005549    0.364213       0.895616                 0.895776   \n",
      "9  0.005554    0.373682       0.905989                 0.905990   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.915101          0.915108      0.976453  LogReg  \n",
      "1              0.913709          0.913709      0.974774  LogReg  \n",
      "2              0.905358          0.905360      0.966887  LogReg  \n",
      "3              0.928323          0.928321      0.973413  LogReg  \n",
      "4              0.919916          0.919911      0.977326  LogReg  \n",
      "5              0.901183          0.901186      0.959952     KNN  \n",
      "6              0.901879          0.901904      0.959133     KNN  \n",
      "7              0.897008          0.896976      0.956774     KNN  \n",
      "8              0.895616          0.895611      0.952423     KNN  \n",
      "9              0.905989          0.905979      0.959363     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.90      0.91      1206\n",
      "      benign       0.90      0.93      0.92      1189\n",
      "\n",
      "    accuracy                           0.92      2395\n",
      "   macro avg       0.92      0.92      0.92      2395\n",
      "weighted avg       0.92      0.92      0.92      2395\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.239554    0.021149       0.915101                 0.915147   \n",
      "1   0.202220    0.009345       0.913709                 0.913709   \n",
      "2   0.188308    0.009803       0.905358                 0.905534   \n",
      "3   0.329162    0.009122       0.928323                 0.928429   \n",
      "4   0.259995    0.009196       0.919916                 0.919914   \n",
      "5   0.091616    0.502946       0.901183                 0.901193   \n",
      "6   0.005744    0.377867       0.901879                 0.902076   \n",
      "7   0.005781    0.356251       0.897008                 0.897227   \n",
      "8   0.005549    0.364213       0.895616                 0.895776   \n",
      "9   0.005554    0.373682       0.905989                 0.905990   \n",
      "10  1.506358    1.261569       0.887961                 0.888612   \n",
      "11  1.462340    1.286884       0.899791                 0.899800   \n",
      "12  1.491945    1.272983       0.902575                 0.903063   \n",
      "13  1.483206    1.251711       0.896312                 0.897903   \n",
      "14  1.489936    1.306814       0.900418                 0.900625   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.915101          0.915108      0.976453  LogReg  \n",
      "1               0.913709          0.913709      0.974774  LogReg  \n",
      "2               0.905358          0.905360      0.966887  LogReg  \n",
      "3               0.928323          0.928321      0.973413  LogReg  \n",
      "4               0.919916          0.919911      0.977326  LogReg  \n",
      "5               0.901183          0.901186      0.959952     KNN  \n",
      "6               0.901879          0.901904      0.959133     KNN  \n",
      "7               0.897008          0.896976      0.956774     KNN  \n",
      "8               0.895616          0.895611      0.952423     KNN  \n",
      "9               0.905989          0.905979      0.959363     KNN  \n",
      "10              0.887961          0.887973      0.962898     SVM  \n",
      "11              0.899791          0.899768      0.965747     SVM  \n",
      "12              0.902575          0.902567      0.963475     SVM  \n",
      "13              0.896312          0.896226      0.961219     SVM  \n",
      "14              0.900418          0.900364      0.966068     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.97      0.98      1206\n",
      "      benign       0.97      1.00      0.98      1189\n",
      "\n",
      "    accuracy                           0.98      2395\n",
      "   macro avg       0.98      0.98      0.98      2395\n",
      "weighted avg       0.98      0.98      0.98      2395\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.239554    0.021149       0.915101                 0.915147   \n",
      "1   0.202220    0.009345       0.913709                 0.913709   \n",
      "2   0.188308    0.009803       0.905358                 0.905534   \n",
      "3   0.329162    0.009122       0.928323                 0.928429   \n",
      "4   0.259995    0.009196       0.919916                 0.919914   \n",
      "5   0.091616    0.502946       0.901183                 0.901193   \n",
      "6   0.005744    0.377867       0.901879                 0.902076   \n",
      "7   0.005781    0.356251       0.897008                 0.897227   \n",
      "8   0.005549    0.364213       0.895616                 0.895776   \n",
      "9   0.005554    0.373682       0.905989                 0.905990   \n",
      "10  1.506358    1.261569       0.887961                 0.888612   \n",
      "11  1.462340    1.286884       0.899791                 0.899800   \n",
      "12  1.491945    1.272983       0.902575                 0.903063   \n",
      "13  1.483206    1.251711       0.896312                 0.897903   \n",
      "14  1.489936    1.306814       0.900418                 0.900625   \n",
      "15  0.025407    0.010559       0.988866                 0.989114   \n",
      "16  0.018460    0.009968       0.987474                 0.987769   \n",
      "17  0.020993    0.010139       0.985386                 0.985806   \n",
      "18  0.024392    0.010206       0.981907                 0.982542   \n",
      "19  0.019510    0.010093       0.986072                 0.986440   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.915101          0.915108      0.976453  LogReg  \n",
      "1               0.913709          0.913709      0.974774  LogReg  \n",
      "2               0.905358          0.905360      0.966887  LogReg  \n",
      "3               0.928323          0.928321      0.973413  LogReg  \n",
      "4               0.919916          0.919911      0.977326  LogReg  \n",
      "5               0.901183          0.901186      0.959952     KNN  \n",
      "6               0.901879          0.901904      0.959133     KNN  \n",
      "7               0.897008          0.896976      0.956774     KNN  \n",
      "8               0.895616          0.895611      0.952423     KNN  \n",
      "9               0.905989          0.905979      0.959363     KNN  \n",
      "10              0.887961          0.887973      0.962898     SVM  \n",
      "11              0.899791          0.899768      0.965747     SVM  \n",
      "12              0.902575          0.902567      0.963475     SVM  \n",
      "13              0.896312          0.896226      0.961219     SVM  \n",
      "14              0.900418          0.900364      0.966068     SVM  \n",
      "15              0.988866          0.988867      0.997962     GNB  \n",
      "16              0.987474          0.987466      0.996387     GNB  \n",
      "17              0.985386          0.985386      0.992435     GNB  \n",
      "18              0.981907          0.981902      0.993075     GNB  \n",
      "19              0.986072          0.986064      0.994986     GNB  \n",
      "60.72462756797904\n"
     ]
    }
   ],
   "source": [
    "## S7: IoT compromised (IoT + IoT)\n",
    " \n",
    "df_malicious = pd.concat([df1,df34])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df21])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign,df_results)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
